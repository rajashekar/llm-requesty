interactions:
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - router.requesty.ai
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://router.requesty.ai/v1/models
  response:
    body:
      string: "{\"object\":\"list\",\"data\":[{\"id\":\"parasail/meta-llama/Llama-4-Scout-17B-16E-Instruct\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":1.4e-7,\"caching_price\":5.8e-7,\"cached_price\":1.4e-7,\"output_price\":5.8e-7,\"max_output_tokens\":1048576,\"context_window\":1048576,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"parasail/parasail-eva-25-72b-v02-fp8\",\"object\":\"model\",\"created\":1741278220,\"owned_by\":\"system\",\"input_price\":7e-7,\"caching_price\":7e-7,\"cached_price\":7e-7,\"output_price\":7e-7,\"max_output_tokens\":8192,\"context_window\":32000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"parasail/parasail-wayfarer-70b-llama33-fp8\",\"object\":\"model\",\"created\":1741278220,\"owned_by\":\"system\",\"input_price\":7e-7,\"caching_price\":7e-7,\"cached_price\":7e-7,\"output_price\":7e-7,\"max_output_tokens\":8192,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"parasail/parasail-qwen25-vl-72b-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":7e-7,\"caching_price\":7e-7,\"cached_price\":7e-7,\"output_price\":7e-7,\"max_output_tokens\":8192,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"parasail/parasail-gemma3-27b-it\",\"object\":\"model\",\"created\":1741963556,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5e-7,\"cached_price\":3e-7,\"output_price\":5e-7,\"max_output_tokens\":8192,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Gemma
        3 1B is the smallest of the new Gemma 3 family. It handles context windows
        up to 32k tokens, understands over 140 languages, and offers improved math,
        reasoning, and chat capabilities, including structured outputs and function
        calling. Note: Gemma 3 1B is not multimodal. For the smallest multimodal Gemma
        3 model, please see [Gemma 3 4B](google/gemma-3-4b-it)\"},{\"id\":\"parasail/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":2.1e-7,\"caching_price\":8.5e-7,\"cached_price\":2.1e-7,\"output_price\":8.5e-7,\"max_output_tokens\":1048576,\"context_window\":1048576,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"parasail/parasail-deepseek-r1\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.000003,\"cached_price\":0.000003,\"output_price\":0.000003,\"max_output_tokens\":8192,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"parasail/parasail-mistral-7b-instruct-03\",\"object\":\"model\",\"created\":1741278220,\"owned_by\":\"system\",\"input_price\":1.1e-7,\"caching_price\":1.1e-7,\"cached_price\":1.1e-7,\"output_price\":1.1e-7,\"max_output_tokens\":8192,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"parasail/parasail-anubis-pro\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":8e-7,\"cached_price\":8e-7,\"output_price\":8e-7,\"max_output_tokens\":8192,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"parasail/parasail-skyfall-36b-v2-fp8\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":5e-7,\"caching_price\":5e-7,\"cached_price\":5e-7,\"output_price\":5e-7,\"max_output_tokens\":8192,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"parasail/parasail-qwen-coder32b-longcontext-128\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":5e-7,\"caching_price\":5e-7,\"cached_price\":5e-7,\"output_price\":5e-7,\"max_output_tokens\":8192,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"parasail/parasail-mistral-nemo\",\"object\":\"model\",\"created\":1741278220,\"owned_by\":\"system\",\"input_price\":1.1e-7,\"caching_price\":1.1e-7,\"cached_price\":1.1e-7,\"output_price\":1.1e-7,\"max_output_tokens\":8192,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"parasail/parasail-mythomax-13b\",\"object\":\"model\",\"created\":1741278220,\"owned_by\":\"system\",\"input_price\":1.1e-7,\"caching_price\":1.1e-7,\"cached_price\":1.1e-7,\"output_price\":1.1e-7,\"max_output_tokens\":8192,\"context_window\":4000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet-20250219\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet-latest@us-east5\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet\",\"object\":\"model\",\"created\":1729558800,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"vertex/google/gemini-2.5-flash\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-pro@europe-west1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/google/gemini-2.5-pro@europe-north1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet-latest@europe-west1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet-latest@us-east5\",\"object\":\"model\",\"created\":1729558800,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"vertex/google/gemini-2.5-flash@europe-west8\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-pro@us-west1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet-latest\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet@europe-west1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/google/gemini-2.5-flash@us-south1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-flash@europe-central2\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-pro@us-south1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet@us-east5\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet-20241022@us-east5\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"vertex/anthropic/claude-4-sonnet-latest\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/google/gemini-2.5-flash@us-central1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-flash@europe-west4\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet-20241022\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet-latest\",\"object\":\"model\",\"created\":1729558800,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"vertex/anthropic/claude-4-sonnet-latest@europe-west1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-4-sonnet\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/google/gemini-2.5-pro\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet@europe-west1\",\"object\":\"model\",\"created\":1729558800,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"vertex/anthropic/claude-4-sonnet-latest@us-east5\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/google/gemini-2.5-pro@europe-west4\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet-20250219@us-east5\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/google/gemini-2.5-flash@us-east1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-pro@us-east5\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/google/gemini-2.5-pro@europe-central2\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet-20241022@europe-west1\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"vertex/anthropic/claude-4-sonnet@europe-west1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-4-sonnet@us-east5\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/google/gemini-2.5-flash@europe-north1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-flash@europe-west1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-pro@us-central1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/google/gemini-2.5-pro@us-east1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/google/gemini-2.5-pro@europe-west8\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet-20250219@europe-west1\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/google/gemini-2.5-flash@us-east5\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-flash@us-west1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet@us-east5\",\"object\":\"model\",\"created\":1729558800,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet-latest@europe-west1\",\"object\":\"model\",\"created\":1729558800,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"alibaba/qwen-plus\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":4e-7,\"caching_price\":4e-7,\"cached_price\":4e-7,\"output_price\":0.0000012,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"alibaba/qwen-turbo\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":5e-8,\"caching_price\":5e-8,\"cached_price\":5e-8,\"output_price\":2e-7,\"max_output_tokens\":0,\"context_window\":1000000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"alibaba/qwen-max\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":0.0000016,\"caching_price\":0.0000016,\"cached_price\":0.0000016,\"output_price\":0.0000064,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"perplexity/sonar\",\"object\":\"model\",\"created\":1741313308,\"owned_by\":\"system\",\"input_price\":0.000001,\"caching_price\":0.000001,\"cached_price\":0.000001,\"output_price\":0.000001,\"max_output_tokens\":8192,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Lightweight
        offering with search grounding, quicker and cheaper than Sonar Pro.\"},{\"id\":\"perplexity/sonar-pro\",\"object\":\"model\",\"created\":1741313308,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.000003,\"cached_price\":0.000003,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":204800,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Premier
        search offering with search grounding, supporting advanced queries and follow-ups.\"},{\"id\":\"perplexity/sonar-reasoning-pro\",\"object\":\"model\",\"created\":1741313308,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":0.000002,\"output_price\":0.000008,\"max_output_tokens\":8192,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Premier
        reasoning offering powered by DeepSeek R1 with Chain of Thought (CoT).\"},{\"id\":\"openai/o3-mini-2025-01-31\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/gpt-4.1-nano\",\"object\":\"model\",\"created\":1744654969,\"owned_by\":\"system\",\"input_price\":1e-7,\"caching_price\":1e-7,\"cached_price\":2.5e-8,\"output_price\":4e-7,\"max_output_tokens\":32768,\"context_window\":1047576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"For
        tasks that demand low latency, GPT\u20114.1 nano is the fastest and cheapest
        model in the GPT-4.1 series. It delivers exceptional performance at a small
        size with its 1 million token context window, and scores 80.1% on MMLU, 50.3%
        on GPQA, and 9.8% on Aider polyglot coding \u2013 even higher than GPT\u20114o
        mini. It\u2019s ideal for tasks like classification or autocompletion.\"},{\"id\":\"openai/o4-mini:low\",\"object\":\"model\",\"created\":1744824542,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":2.75e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/gpt-4.1-nano-2025-04-14\",\"object\":\"model\",\"created\":1744654969,\"owned_by\":\"system\",\"input_price\":1e-7,\"caching_price\":1e-7,\"cached_price\":2.5e-8,\"output_price\":4e-7,\"max_output_tokens\":32768,\"context_window\":1047576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"For
        tasks that demand low latency, GPT\u20114.1 nano is the fastest and cheapest
        model in the GPT-4.1 series. It delivers exceptional performance at a small
        size with its 1 million token context window, and scores 80.1% on MMLU, 50.3%
        on GPQA, and 9.8% on Aider polyglot coding \u2013 even higher than GPT\u20114o
        mini. It\u2019s ideal for tasks like classification or autocompletion.\"},{\"id\":\"openai/o4-mini\",\"object\":\"model\",\"created\":1744824542,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":2.75e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/o4-mini:flex\",\"object\":\"model\",\"created\":1744824542,\"owned_by\":\"system\",\"input_price\":5.5e-7,\"caching_price\":5.5e-7,\"cached_price\":1.38e-7,\"output_price\":0.0000022,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/gpt-4o-mini-2024-07-18\",\"object\":\"model\",\"created\":1721264400,\"owned_by\":\"system\",\"input_price\":1.5e-7,\"caching_price\":1.5e-7,\"cached_price\":7.5e-8,\"output_price\":6e-7,\"max_output_tokens\":16384,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"GPT-4o
        mini is OpenAI's newest model after [GPT-4 Omni](/models/openai/gpt-4o), supporting
        both text and image inputs with text outputs.\\n\\nAs their most advanced
        small model, it is many multiples more affordable than other recent frontier
        models, and more than 60% cheaper than [GPT-3.5 Turbo](/models/openai/gpt-3.5-turbo).
        It maintains SOTA intelligence, while being significantly more cost-effective.\\n\\nGPT-4o
        mini achieves an 82% score on MMLU and presently ranks higher than GPT-4 on
        chat preferences [common leaderboards](https://arena.lmsys.org/).\\n\\nCheck
        out the [launch announcement](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)
        to learn more.\\n\\n#multimodal\"},{\"id\":\"openai/gpt-4.1\",\"object\":\"model\",\"created\":1744654985,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":5e-7,\"output_price\":0.000008,\"max_output_tokens\":32768,\"context_window\":1047576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"GPT-4.1
        is a flagship large language model optimized for advanced instruction following,
        real-world software engineering, and long-context reasoning. It supports a
        1 million token context window and outperforms GPT-4o and GPT-4.5 across coding
        (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal
        understanding benchmarks. It is tuned for precise code diffs, agent reliability,
        and high recall in large document contexts, making it ideal for agents, IDE
        tooling, and enterprise knowledge retrieval.\"},{\"id\":\"openai/o3-2025-04-16\",\"object\":\"model\",\"created\":1744827057,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":5e-7,\"output_price\":0.000008,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023.\"},{\"id\":\"openai/o3-mini\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/o1:medium\",\"object\":\"model\",\"created\":1734459999,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.000015,\"cached_price\":0.0000075,\"output_price\":0.00006,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023.\"},{\"id\":\"openai/gpt-4o-2024-08-06\",\"object\":\"model\",\"created\":1732127594,\"owned_by\":\"system\",\"input_price\":0.0000025,\"caching_price\":0.0000025,\"cached_price\":0.00000125,\"output_price\":0.00001,\"max_output_tokens\":16384,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        2024-11-20 version of GPT-4o offers a leveled-up creative writing ability
        with more natural, engaging, and tailored writing to improve relevance \\u0026
        readability. It\u2019s also better at working with uploaded files, providing
        deeper insights \\u0026 more thorough responses.\\n\\nGPT-4o (\\\"o\\\" for
        \\\"omni\\\") is OpenAI's latest AI model, supporting both text and image
        inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo)
        while being twice as fast and 50% more cost-effective. GPT-4o also offers
        improved performance in processing non-English languages and enhanced visual
        capabilities.\"},{\"id\":\"openai/gpt-4o-2024-05-13\",\"object\":\"model\",\"created\":1732127594,\"owned_by\":\"system\",\"input_price\":0.0000025,\"caching_price\":0.0000025,\"cached_price\":0.0000025,\"output_price\":0.00001,\"max_output_tokens\":4096,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        2024-11-20 version of GPT-4o offers a leveled-up creative writing ability
        with more natural, engaging, and tailored writing to improve relevance \\u0026
        readability. It\u2019s also better at working with uploaded files, providing
        deeper insights \\u0026 more thorough responses.\\n\\nGPT-4o (\\\"o\\\" for
        \\\"omni\\\") is OpenAI's latest AI model, supporting both text and image
        inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo)
        while being twice as fast and 50% more cost-effective. GPT-4o also offers
        improved performance in processing non-English languages and enhanced visual
        capabilities.\"},{\"id\":\"openai/gpt-4o\",\"object\":\"model\",\"created\":1732127594,\"owned_by\":\"system\",\"input_price\":0.0000025,\"caching_price\":0.0000025,\"cached_price\":0.00000125,\"output_price\":0.00001,\"max_output_tokens\":16384,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        2024-11-20 version of GPT-4o offers a leveled-up creative writing ability
        with more natural, engaging, and tailored writing to improve relevance \\u0026
        readability. It\u2019s also better at working with uploaded files, providing
        deeper insights \\u0026 more thorough responses.\\n\\nGPT-4o (\\\"o\\\" for
        \\\"omni\\\") is OpenAI's latest AI model, supporting both text and image
        inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo)
        while being twice as fast and 50% more cost-effective. GPT-4o also offers
        improved performance in processing non-English languages and enhanced visual
        capabilities.\"},{\"id\":\"openai/o1-mini\",\"object\":\"model\",\"created\":1726102800,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":65536,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023. o1-mini is a faster and more affordable reasoning
        model, but OpenAI recommends using the newer o3-mini model that features higher
        intelligence at the same latency and price as o1-mini.\"},{\"id\":\"openai/o4-mini:medium\",\"object\":\"model\",\"created\":1744824542,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":2.75e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/o1\",\"object\":\"model\",\"created\":1734459999,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.000015,\"cached_price\":0.0000075,\"output_price\":0.00006,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023.\"},{\"id\":\"openai/o4-mini:high\",\"object\":\"model\",\"created\":1744824542,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":2.75e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/o1:low\",\"object\":\"model\",\"created\":1734459999,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.000015,\"cached_price\":0.0000075,\"output_price\":0.00006,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023.\"},{\"id\":\"openai/gpt-4o-mini\",\"object\":\"model\",\"created\":1721264400,\"owned_by\":\"system\",\"input_price\":1.5e-7,\"caching_price\":1.5e-7,\"cached_price\":7.5e-8,\"output_price\":6e-7,\"max_output_tokens\":16384,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"GPT-4o
        mini is OpenAI's newest model after [GPT-4 Omni](/models/openai/gpt-4o), supporting
        both text and image inputs with text outputs.\\n\\nAs their most advanced
        small model, it is many multiples more affordable than other recent frontier
        models, and more than 60% cheaper than [GPT-3.5 Turbo](/models/openai/gpt-3.5-turbo).
        It maintains SOTA intelligence, while being significantly more cost-effective.\\n\\nGPT-4o
        mini achieves an 82% score on MMLU and presently ranks higher than GPT-4 on
        chat preferences [common leaderboards](https://arena.lmsys.org/).\\n\\nCheck
        out the [launch announcement](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)
        to learn more.\\n\\n#multimodal\"},{\"id\":\"openai/o3-mini:low\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/gpt-4o-2024-11-20\",\"object\":\"model\",\"created\":1732127594,\"owned_by\":\"system\",\"input_price\":0.0000025,\"caching_price\":0.0000025,\"cached_price\":0.00000125,\"output_price\":0.00001,\"max_output_tokens\":16384,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        2024-11-20 version of GPT-4o offers a leveled-up creative writing ability
        with more natural, engaging, and tailored writing to improve relevance \\u0026
        readability. It\u2019s also better at working with uploaded files, providing
        deeper insights \\u0026 more thorough responses.\\n\\nGPT-4o (\\\"o\\\" for
        \\\"omni\\\") is OpenAI's latest AI model, supporting both text and image
        inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo)
        while being twice as fast and 50% more cost-effective. GPT-4o also offers
        improved performance in processing non-English languages and enhanced visual
        capabilities.\"},{\"id\":\"openai/o3-mini:high\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/o3-pro\",\"object\":\"model\",\"created\":1749601952,\"owned_by\":\"system\",\"input_price\":0.00002,\"caching_price\":0.00002,\"cached_price\":0.00002,\"output_price\":0.00008,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":false,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o3 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023.\"},{\"id\":\"openai/o1:high\",\"object\":\"model\",\"created\":1734459999,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.000015,\"cached_price\":0.0000075,\"output_price\":0.00006,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023.\"},{\"id\":\"openai/chatgpt-4o-latest\",\"object\":\"model\",\"created\":1723597200,\"owned_by\":\"system\",\"input_price\":0.000005,\"caching_price\":0.000005,\"cached_price\":0.000005,\"output_price\":0.000015,\"max_output_tokens\":16000,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"OpenAI
        ChatGPT 4o is continually updated by OpenAI to point to the current version
        of GPT-4o used by ChatGPT. It therefore differs slightly from the API version
        of [GPT-4o](/models/openai/gpt-4o) in that it has additional RLHF. It is intended
        for research and evaluation.\\n\\nOpenAI notes that this model is not suited
        for production use-cases as it may be removed or redirected to another model
        in the future.\"},{\"id\":\"openai/gpt-4.1-mini-2025-04-14\",\"object\":\"model\",\"created\":1744654981,\"owned_by\":\"system\",\"input_price\":4e-7,\"caching_price\":4e-7,\"cached_price\":1e-7,\"output_price\":0.0000016,\"max_output_tokens\":32768,\"context_window\":1047576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"GPT-4.1
        Mini is a mid-sized model delivering performance competitive with GPT-4o at
        substantially lower latency and cost. It retains a 1 million token context
        window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge,
        and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on
        Aider\u2019s polyglot diff benchmark) and vision understanding, making it
        suitable for interactive applications with tight performance constraints.\"},{\"id\":\"openai/gpt-4.1-mini\",\"object\":\"model\",\"created\":1744654981,\"owned_by\":\"system\",\"input_price\":4e-7,\"caching_price\":4e-7,\"cached_price\":1e-7,\"output_price\":0.0000016,\"max_output_tokens\":32768,\"context_window\":1047576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"GPT-4.1
        Mini is a mid-sized model delivering performance competitive with GPT-4o at
        substantially lower latency and cost. It retains a 1 million token context
        window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge,
        and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on
        Aider\u2019s polyglot diff benchmark) and vision understanding, making it
        suitable for interactive applications with tight performance constraints.\"},{\"id\":\"openai/o3-mini:medium\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/o1-2024-12-17\",\"object\":\"model\",\"created\":1734459999,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.000015,\"cached_price\":0.0000075,\"output_price\":0.00006,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023.\"},{\"id\":\"openai/o4-mini-2025-04-16\",\"object\":\"model\",\"created\":1744824542,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":2.75e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/gpt-4.1-2025-04-14\",\"object\":\"model\",\"created\":1744654985,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":5e-7,\"output_price\":0.000008,\"max_output_tokens\":32768,\"context_window\":1047576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"GPT-4.1
        is a flagship large language model optimized for advanced instruction following,
        real-world software engineering, and long-context reasoning. It supports a
        1 million token context window and outperforms GPT-4o and GPT-4.5 across coding
        (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal
        understanding benchmarks. It is tuned for precise code diffs, agent reliability,
        and high recall in large document contexts, making it ideal for agents, IDE
        tooling, and enterprise knowledge retrieval.\"},{\"id\":\"openai/gpt-4.5-preview\",\"object\":\"model\",\"created\":1740687810,\"owned_by\":\"system\",\"input_price\":0.000075,\"caching_price\":0.000075,\"cached_price\":0.0000375,\"output_price\":0.00015,\"max_output_tokens\":4096,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"GPT-4.5
        (Preview) is a research preview of OpenAI\u2019s latest language model, designed
        to advance capabilities in reasoning, creativity, and multi-turn conversation.
        It builds on previous iterations with improvements in world knowledge, contextual
        coherence, and the ability to follow user intent more effectively.\\n\\nThe
        model demonstrates enhanced performance in tasks that require open-ended thinking,
        problem-solving, and communication. Early testing suggests it is better at
        generating nuanced responses, maintaining long-context coherence, and reducing
        hallucinations compared to earlier versions.\\n\\nThis research preview is
        intended to help evaluate GPT-4.5\u2019s strengths and limitations in real-world
        use cases as OpenAI continues to refine and develop future models. Read more
        at the [blog post here.](https://openai.com/index/introducing-gpt-4-5/)\"},{\"id\":\"openai/o3:flex\",\"object\":\"model\",\"created\":1744827057,\"owned_by\":\"system\",\"input_price\":0.000001,\"caching_price\":0.000001,\"cached_price\":2.5e-7,\"output_price\":0.000004,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"O3
        Flex is a cheaper version of the o3 model\"},{\"id\":\"openai/o1-mini-2024-09-12\",\"object\":\"model\",\"created\":1726102800,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":65536,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023. o1-mini is a faster and more affordable reasoning
        model, but OpenAI recommends using the newer o3-mini model that features higher
        intelligence at the same latency and price as o1-mini.\"},{\"id\":\"openai/o3\",\"object\":\"model\",\"created\":1744827057,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":5e-7,\"output_price\":0.000008,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023.\"},{\"id\":\"together/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":1.8e-7,\"caching_price\":1.8e-7,\"cached_price\":1.8e-7,\"output_price\":1.8e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/meta-llama/Llama-3.2-3B-Instruct-Turbo\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":6e-8,\"caching_price\":6e-8,\"cached_price\":6e-8,\"output_price\":6e-8,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/Qwen/Qwen2.5-72B-Instruct-Turbo\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":0.0000012,\"caching_price\":0.0000012,\"cached_price\":0.0000012,\"output_price\":0.0000012,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"together/meta-llama/Llama-3-70b-chat-hf\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8.8e-7,\"caching_price\":8.8e-7,\"cached_price\":8.8e-7,\"output_price\":8.8e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/deepseek-ai/DeepSeek-V3\",\"object\":\"model\",\"created\":1748631837,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.00000125,\"cached_price\":0.00000125,\"output_price\":0.00000125,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"together/Qwen/Qwen2-72B-Instruct\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":9e-7,\"caching_price\":9e-7,\"cached_price\":9e-7,\"output_price\":9e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"together/deepseek-llm-67b-chat\",\"object\":\"model\",\"created\":1717095837,\"owned_by\":\"system\",\"input_price\":9e-7,\"caching_price\":9e-7,\"cached_price\":9e-7,\"output_price\":9e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"together/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":0.0000035,\"caching_price\":0.0000035,\"cached_price\":0.0000035,\"output_price\":0.0000035,\"max_output_tokens\":0,\"context_window\":130815,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/meta-llama/Llama-2-70b-hf\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":9e-7,\"caching_price\":9e-7,\"cached_price\":9e-7,\"output_price\":9e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/meta-llama/Llama-3.3-70B-Instruct-Turbo\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8.8e-7,\"caching_price\":8.8e-7,\"cached_price\":8.8e-7,\"output_price\":8.8e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/deepseek-ai/DeepSeek-R1\",\"object\":\"model\",\"created\":1748631837,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.000007,\"cached_price\":0.000003,\"output_price\":0.000007,\"max_output_tokens\":8192,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"together/meta-llama/LlamaGuard-2-8b\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":2e-7,\"caching_price\":2e-7,\"cached_price\":2e-7,\"output_price\":2e-7,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/Qwen/Qwen2.5-Coder-32B-Instruct\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":8e-7,\"cached_price\":8e-7,\"output_price\":8e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"together/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8.8e-7,\"caching_price\":8.8e-7,\"cached_price\":8.8e-7,\"output_price\":8.8e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":6e-7,\"caching_price\":6e-7,\"cached_price\":6e-7,\"output_price\":6e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepHermes
        3 (Mistral 24B Preview) is an instruction-tuned language model by Nous Research
        based on Mistral-Small-24B, designed for chat, function calling, and advanced
        multi-turn reasoning. It introduces a dual-mode system that toggles between
        intuitive chat responses and structured \u201Cdeep reasoning\u201D mode using
        special system prompts. Fine-tuned via distillation from R1, it supports structured
        output (JSON mode) and function call syntax for agent-based applications.\\n\\nDeepHermes
        3 supports a **reasoning toggle via system prompt**, allowing users to switch
        between fast, intuitive responses and deliberate, multi-step reasoning. When
        activated with the following specific system instruction, the model enters
        a *\\\"deep thinking\\\"* mode\u2014generating extended chains of thought
        wrapped in `\\u003cthink\\u003e\\u003c/think\\u003e` tags before delivering
        a final answer. \\n\\nSystem Prompt: You are a deep thinking AI, you may use
        extremely long chains of thought to deeply consider the problem and deliberate
        with yourself via systematic reasoning processes to help come to a correct
        solution prior to answering. You should enclose your thoughts and internal
        monologue inside \\u003cthink\\u003e \\u003c/think\\u003e tags, and then provide
        your solution or response to the problem.\"},{\"id\":\"together/meta-llama/Meta-Llama-3-70B-Instruct-Turbo\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8.8e-7,\"caching_price\":8.8e-7,\"cached_price\":8.8e-7,\"output_price\":8.8e-7,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/upstage/SOLAR-10.7B-Instruct-v1.0\",\"object\":\"model\",\"created\":1736964224,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":3e-7,\"cached_price\":3e-7,\"output_price\":3e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"together/Qwen/QwQ-32B-Preview\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":0.0000012,\"caching_price\":0.0000012,\"cached_price\":0.0000012,\"output_price\":0.0000012,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"together/meta-llama/Meta-Llama-3-70B-Instruct-Lite\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":5.4e-7,\"caching_price\":5.4e-7,\"cached_price\":5.4e-7,\"output_price\":5.4e-7,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/meta-llama/Llama-2-7b-chat-hf\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":2e-7,\"caching_price\":2e-7,\"cached_price\":2e-7,\"output_price\":2e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/meta-llama/Meta-Llama-3-8B-Instruct-Lite\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":1e-7,\"caching_price\":1e-7,\"cached_price\":1e-7,\"output_price\":1e-7,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/meta-llama/Llama-3-8b-chat-hf\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":2e-7,\"caching_price\":2e-7,\"cached_price\":2e-7,\"output_price\":2e-7,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/meta-llama/Llama-2-13b-chat-hf\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":2.2e-7,\"caching_price\":2.2e-7,\"cached_price\":2.2e-7,\"output_price\":2.2e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\",\"object\":\"model\",\"created\":1744123094,\"owned_by\":\"system\",\"input_price\":8.8e-7,\"caching_price\":8.8e-7,\"cached_price\":8.8e-7,\"output_price\":8.8e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Llama-3.3-Nemotron-Super-49B-v1
        is a large language model (LLM) optimized for advanced reasoning, conversational
        interactions, retrieval-augmented generation (RAG), and tool-calling tasks.
        Derived from Meta's Llama-3.3-70B-Instruct, it employs a Neural Architecture
        Search (NAS) approach, significantly enhancing efficiency and reducing memory
        requirements. This allows the model to support a context length of up to 128K
        tokens and fit efficiently on single high-performance GPUs, such as NVIDIA
        H200.\\n\\nNote: you must include `detailed thinking on` in the system prompt
        to enable reasoning. Please see [Usage Recommendations](https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1#quick-start-and-usage-recommendations)
        for more.\"},{\"id\":\"together/Qwen/Qwen2.5-7B-Instruct-Turbo\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":3e-7,\"cached_price\":3e-7,\"output_price\":3e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"together/meta-llama/Meta-Llama-Guard-3-8B\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":2e-7,\"caching_price\":2e-7,\"cached_price\":2e-7,\"output_price\":2e-7,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"deepinfra/deepseek-ai/DeepSeek-R1\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8.5e-7,\"caching_price\":8.5e-7,\"cached_price\":8.5e-7,\"output_price\":0.0000025,\"max_output_tokens\":8192,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"deepinfra/meta-llama/Meta-Llama-3.1-405B-Instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":8e-7,\"cached_price\":8e-7,\"output_price\":8e-7,\"max_output_tokens\":0,\"context_window\":130815,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"deepinfra/Qwen/Qwen3-235B-A22B\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":2e-7,\"caching_price\":2e-7,\"cached_price\":2e-7,\"output_price\":6e-7,\"max_output_tokens\":4096,\"context_window\":40000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"deepinfra/Qwen/QwQ-32B\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":1.2e-7,\"caching_price\":1.2e-7,\"cached_price\":1.2e-7,\"output_price\":1.8e-7,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"deepinfra/Qwen/Qwen3-32B\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":1e-7,\"caching_price\":1e-7,\"cached_price\":1e-7,\"output_price\":3e-7,\"max_output_tokens\":0,\"context_window\":40000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\"object\":\"model\",\"created\":1715697754,\"owned_by\":\"system\",\"input_price\":2e-8,\"caching_price\":2e-8,\"cached_price\":2e-8,\"output_price\":5e-8,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":2.3e-7,\"caching_price\":2.3e-7,\"cached_price\":2.3e-7,\"output_price\":4e-7,\"max_output_tokens\":0,\"context_window\":130815,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"deepinfra/Qwen/Qwen2.5-72B-Instruct\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":2.3e-7,\"caching_price\":2.3e-7,\"cached_price\":2.3e-7,\"output_price\":4e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"deepinfra/meta-llama/Llama-3.3-70B-Instruct-Turbo\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":1.2e-7,\"caching_price\":1.2e-7,\"cached_price\":1.2e-7,\"output_price\":3e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"deepinfra/microsoft/WizardLM-2-8x22B\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":5e-7,\"caching_price\":5e-7,\"cached_price\":5e-7,\"output_price\":5e-7,\"max_output_tokens\":4096,\"context_window\":65536,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Phi-4-reasoning-plus
        is an enhanced 14B parameter model from Microsoft, fine-tuned from Phi-4 with
        additional reinforcement learning to boost accuracy on math, science, and
        code reasoning tasks. It uses the same dense decoder-only transformer architecture
        as Phi-4, but generates longer, more comprehensive outputs structured into
        a step-by-step reasoning trace and final answer.\\n\\nWhile it offers improved
        benchmark scores over Phi-4-reasoning across tasks like AIME, OmniMath, and
        HumanEvalPlus, its responses are typically ~50% longer, resulting in higher
        latency. Designed for English-only applications, it is well-suited for structured
        reasoning workflows where output quality takes priority over response speed.\"},{\"id\":\"deepinfra/Qwen/Qwen2.5-Coder-32B-Instruct\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":7e-8,\"caching_price\":7e-8,\"cached_price\":7e-8,\"output_price\":1.6e-7,\"max_output_tokens\":0,\"context_window\":16384,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"deepinfra/meta-llama/Llama-3.2-11B-Vision-Instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":5.5e-8,\"caching_price\":5.5e-8,\"cached_price\":5.5e-8,\"output_price\":5.5e-8,\"max_output_tokens\":4096,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"deepinfra/meta-llama/Llama-3.2-90B-Vision-Instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":3.5e-7,\"caching_price\":3.5e-7,\"cached_price\":3.5e-7,\"output_price\":4e-7,\"max_output_tokens\":4096,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"deepinfra/deepseek-ai/DeepSeek-R1-Distill-Llama-70B\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":2.3e-7,\"caching_price\":2.3e-7,\"cached_price\":2.3e-7,\"output_price\":6.9e-7,\"max_output_tokens\":8192,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"deepinfra/deepseek-ai/DeepSeek-V3\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8.5e-7,\"caching_price\":8.5e-7,\"cached_price\":8.5e-7,\"output_price\":9e-7,\"max_output_tokens\":8192,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"deepinfra/microsoft/phi-4\",\"object\":\"model\",\"created\":1746134561,\"owned_by\":\"system\",\"input_price\":7e-8,\"caching_price\":7e-8,\"cached_price\":7e-8,\"output_price\":1.4e-7,\"max_output_tokens\":0,\"context_window\":16384,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Phi-4-reasoning-plus
        is an enhanced 14B parameter model from Microsoft, fine-tuned from Phi-4 with
        additional reinforcement learning to boost accuracy on math, science, and
        code reasoning tasks. It uses the same dense decoder-only transformer architecture
        as Phi-4, but generates longer, more comprehensive outputs structured into
        a step-by-step reasoning trace and final answer.\\n\\nWhile it offers improved
        benchmark scores over Phi-4-reasoning across tasks like AIME, OmniMath, and
        HumanEvalPlus, its responses are typically ~50% longer, resulting in higher
        latency. Designed for English-only applications, it is well-suited for structured
        reasoning workflows where output quality takes priority over response speed.\"},{\"id\":\"deepinfra/meta-llama/Llama-3.3-70B-Instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":2.3e-7,\"caching_price\":2.3e-7,\"cached_price\":2.3e-7,\"output_price\":4e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"deepinfra/nvidia/Llama-3.1-Nemotron-70B-Instruct\",\"object\":\"model\",\"created\":1744123094,\"owned_by\":\"system\",\"input_price\":1.2e-7,\"caching_price\":1.2e-7,\"cached_price\":1.2e-7,\"output_price\":3e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Llama-3.3-Nemotron-Super-49B-v1
        is a large language model (LLM) optimized for advanced reasoning, conversational
        interactions, retrieval-augmented generation (RAG), and tool-calling tasks.
        Derived from Meta's Llama-3.3-70B-Instruct, it employs a Neural Architecture
        Search (NAS) approach, significantly enhancing efficiency and reducing memory
        requirements. This allows the model to support a context length of up to 128K
        tokens and fit efficiently on single high-performance GPUs, such as NVIDIA
        H200.\\n\\nNote: you must include `detailed thinking on` in the system prompt
        to enable reasoning. Please see [Usage Recommendations](https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1#quick-start-and-usage-recommendations)
        for more.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet@us-west-2\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-20250514@eu-west-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet@eu-west-1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-latest@eu-central-1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-latest@eu-west-1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-opus\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-latest@us-west-2\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet@eu-west-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-latest@us-east-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-latest@eu-north-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-latest@us-east-2\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-latest@eu-west-3\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-latest@us-west-2\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-opus-latest@us-east-2\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-4-opus@us-east-2\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet@us-east-2\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-20250219@eu-central-1\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-20250514@us-east-2\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-latest@eu-west-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-20250219@us-east-1\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-20250514@eu-north-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-latest@us-east-2\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-opus@us-west-2\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet@us-east-1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-20250514@us-east-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-opus-latest@us-east-1\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-20250219@eu-west-1\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet@eu-west-3\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-opus-latest\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-4-opus-latest@us-west-2\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-latest@eu-north-1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-opus-20250514\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-20250219@us-west-2\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-latest\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet@us-west-2\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-20250219@eu-north-1\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-latest@eu-central-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-latest\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet@eu-central-1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-20250219\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-20250219@eu-west-3\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-20250514@eu-west-3\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-20250514@us-west-2\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet@us-east-2\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet@eu-north-1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-opus-20250514@us-east-1\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-4-opus-20250514@us-east-2\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-4-opus-20250514@us-west-2\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet@us-east-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-20250514@eu-central-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet@eu-west-3\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-20250514\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-latest@eu-west-3\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-opus@us-east-1\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet@eu-central-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-20250219@us-east-2\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-latest@us-east-1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet@eu-north-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"netmind/deepseek-ai/DeepSeek-R1-0528\",\"object\":\"model\",\"created\":1748631837,\"owned_by\":\"system\",\"input_price\":5e-7,\"caching_price\":5e-7,\"cached_price\":5e-7,\"output_price\":0.000001,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"DeepSeek
        R1 is the latest open-source model released by the DeepSeek team, featuring
        impressive reasoning capabilities, particularly achieving performance comparable
        to OpenAI's o1 model in mathematics, coding, and reasoning tasks.\"},{\"id\":\"xai/grok-3-mini-fast-beta:high\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":6e-7,\"caching_price\":6e-7,\"cached_price\":6e-7,\"output_price\":0.000004,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"xai/grok-3-mini-beta:low\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":3e-7,\"cached_price\":3e-7,\"output_price\":5e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"xai/grok-3-mini-beta:high\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":3e-7,\"cached_price\":3e-7,\"output_price\":5e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"xai/grok-3-fast-beta\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":0.000005,\"caching_price\":0.000005,\"cached_price\":0.000005,\"output_price\":0.000025,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"xai/grok-2-1212\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":0.000002,\"output_price\":0.00001,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"xai/grok-2-latest\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":0.000002,\"output_price\":0.00001,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"xai/grok-3-mini-beta\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":3e-7,\"cached_price\":3e-7,\"output_price\":5e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"xai/grok-4\",\"object\":\"model\",\"created\":1752171508,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.000003,\"cached_price\":7.5e-7,\"output_price\":0.000015,\"max_output_tokens\":0,\"context_window\":256000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"xai/grok-3-mini-fast-beta\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":6e-7,\"caching_price\":6e-7,\"cached_price\":6e-7,\"output_price\":0.000004,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"xai/grok-3-beta\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.000003,\"cached_price\":0.000003,\"output_price\":0.000015,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"xai/grok-3-mini-fast-beta:low\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":6e-7,\"caching_price\":6e-7,\"cached_price\":6e-7,\"output_price\":0.000004,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"cline/claude-3-7-sonnet:1024\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/o3-mini:low\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"cline/o3-mini\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"cline/claude-3-7-sonnet\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/o3-mini:medium\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"cline/o3-mini:high\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"cline/claude-3-7-sonnet:max\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/claude-3-7-sonnet:low\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/claude-3-7-sonnet:medium\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/claude-3-7-sonnet:16384\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/deepseek-reasoner:alpha\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":5.5e-7,\"caching_price\":5.5e-7,\"cached_price\":1.4e-7,\"output_price\":0.00000219,\"max_output_tokens\":8000,\"context_window\":64000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Fully
        open-source model \\u0026 technical report. Performance on par with OpenAI-o1.\"},{\"id\":\"cline/claude-3-7-sonnet:8192\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/claude-3-7-sonnet:high\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/claude-3-7-sonnet:64000\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"mistral/devstral-small-latest\",\"object\":\"model\",\"created\":1736964224,\"owned_by\":\"system\",\"input_price\":1e-7,\"caching_price\":1e-7,\"cached_price\":1e-7,\"output_price\":3e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"mistral/mistral-small-latest\",\"object\":\"model\",\"created\":1708792361,\"owned_by\":\"system\",\"input_price\":1e-7,\"caching_price\":1e-7,\"cached_price\":1e-7,\"output_price\":3e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Magistral
        Small is a 24B parameter instruction-tuned model based on Mistral-Small-3.1
        (2503), enhanced through supervised fine-tuning on traces from Magistral Medium
        and further refined via reinforcement learning. It is optimized for reasoning
        and supports a wide multilingual range, including over 20 languages.\"},{\"id\":\"mistral/open-mistral-7b\",\"object\":\"model\",\"created\":1708792361,\"owned_by\":\"system\",\"input_price\":2.5e-7,\"caching_price\":2.5e-7,\"cached_price\":2.5e-7,\"output_price\":2.5e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Magistral
        Small is a 24B parameter instruction-tuned model based on Mistral-Small-3.1
        (2503), enhanced through supervised fine-tuning on traces from Magistral Medium
        and further refined via reinforcement learning. It is optimized for reasoning
        and supports a wide multilingual range, including over 20 languages.\"},{\"id\":\"mistral/mistral-large-latest\",\"object\":\"model\",\"created\":1708792361,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":0.000002,\"output_price\":0.000006,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Magistral
        Small is a 24B parameter instruction-tuned model based on Mistral-Small-3.1
        (2503), enhanced through supervised fine-tuning on traces from Magistral Medium
        and further refined via reinforcement learning. It is optimized for reasoning
        and supports a wide multilingual range, including over 20 languages.\"},{\"id\":\"anthropic/claude-3-opus-20240229\",\"object\":\"model\",\"created\":1730678400,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":4096,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Powerful
        model for highly complex tasks. Top-level intelligence, fluency, and understanding.\"},{\"id\":\"anthropic/claude-3-sonnet-20240229\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.000003,\"cached_price\":0.000003,\"output_price\":0.000015,\"max_output_tokens\":4096,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Balance
        of intelligence and speed. Strong utility, balanced for scaled deployments\"},{\"id\":\"anthropic/claude-3-5-haiku-latest\",\"object\":\"model\",\"created\":1730678400,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":0.000001,\"cached_price\":8e-8,\"output_price\":0.000004,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Anthropic's
        fastest model. Intelligence at blazing speeds.\"},{\"id\":\"anthropic/claude-sonnet-4-20250514\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Sonnet 4 significantly improves on Sonnet 3.7's industry-leading capabilities,
        excelling in coding with a state-of-the-art 72.7% on SWE-bench. The model
        balances performance and efficiency for internal and external use cases, with
        enhanced steerability for greater control over implementations.\"},{\"id\":\"anthropic/claude-3-5-sonnet-20241022\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"anthropic/claude-3-7-sonnet-latest\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"anthropic/claude-3-5-haiku-20241022\",\"object\":\"model\",\"created\":1730678400,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":0.000001,\"cached_price\":8e-8,\"output_price\":0.000004,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Anthropic's
        fastest model. Intelligence at blazing speeds.\"},{\"id\":\"anthropic/claude-3-haiku-20240307\",\"object\":\"model\",\"created\":1730678400,\"owned_by\":\"system\",\"input_price\":2.5e-7,\"caching_price\":3e-7,\"cached_price\":3e-8,\"output_price\":0.00000125,\"max_output_tokens\":4096,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Fastest
        and most compact model for near-instant responsiveness. Quick and accurate
        targeted performance.\"},{\"id\":\"anthropic/claude-3-5-sonnet-20240620\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"anthropic/claude-3-opus-latest\",\"object\":\"model\",\"created\":1709596800,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":4096,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Powerful
        model for highly complex tasks. Top-level intelligence, fluency, and understanding.\"},{\"id\":\"anthropic/claude-opus-4-20250514\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"anthropic/claude-3-5-sonnet-latest\",\"object\":\"model\",\"created\":1729558800,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"anthropic/claude-3-7-sonnet-20250219\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"google/gemini-2.5-pro\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"google/gemini-2.5-flash-lite-preview-06-17\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":1e-7,\"caching_price\":3.5e-7,\"cached_price\":2.5e-8,\"output_price\":4e-7,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        smallest and most cost effective model, built for at scale usage.\"},{\"id\":\"google/gemini-1.5-flash-8b-latest\",\"object\":\"model\",\"created\":1744918267,\"owned_by\":\"system\",\"input_price\":3.75e-8,\"caching_price\":3.75e-8,\"cached_price\":3.75e-8,\"output_price\":1.5e-7,\"max_output_tokens\":8192,\"context_window\":1048576,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"google/gemini-1.5-flash-8b\",\"object\":\"model\",\"created\":1744918267,\"owned_by\":\"system\",\"input_price\":7.5e-8,\"caching_price\":7.5e-8,\"cached_price\":7.5e-8,\"output_price\":3e-7,\"max_output_tokens\":8192,\"context_window\":1048576,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"google/gemini-1.5-pro-latest\",\"object\":\"model\",\"created\":1717604857,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.00000125,\"cached_price\":0.00000125,\"output_price\":0.000005,\"max_output_tokens\":8192,\"context_window\":2097152,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"google/gemini-2.5-flash\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"google/gemini-1.5-pro\",\"object\":\"model\",\"created\":1717604857,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.00000125,\"cached_price\":0.00000125,\"output_price\":0.000005,\"max_output_tokens\":8192,\"context_window\":2097152,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"google/gemini-2.0-flash-001\",\"object\":\"model\",\"created\":1738769413,\"owned_by\":\"system\",\"input_price\":1e-7,\"caching_price\":1e-7,\"cached_price\":1e-7,\"output_price\":4e-7,\"max_output_tokens\":8192,\"context_window\":1048576,\"supports_caching\":false,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Gemini
        Flash 2.0 offers a significantly faster time to first token (TTFT) compared
        to [Gemini Flash 1.5](/google/gemini-flash-1.5), while maintaining quality
        on par with larger models like [Gemini Pro 1.5](/google/gemini-pro-1.5). It
        introduces notable enhancements in multimodal understanding, coding capabilities,
        complex instruction following, and function calling. These advancements come
        together to deliver more seamless and robust agentic experiences.\"},{\"id\":\"google/gemini-1.5-flash\",\"object\":\"model\",\"created\":1744918267,\"owned_by\":\"system\",\"input_price\":7.5e-8,\"caching_price\":7.5e-8,\"cached_price\":7.5e-8,\"output_price\":3e-7,\"max_output_tokens\":8192,\"context_window\":1048576,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"google/gemini-1.5-flash-latest\",\"object\":\"model\",\"created\":1744918267,\"owned_by\":\"system\",\"input_price\":7.5e-8,\"caching_price\":7.5e-8,\"cached_price\":7.5e-8,\"output_price\":3e-7,\"max_output_tokens\":8192,\"context_window\":1048576,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"deepseek/deepseek-reasoner\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":5.5e-7,\"caching_price\":5.5e-7,\"cached_price\":1.4e-7,\"output_price\":0.00000219,\"max_output_tokens\":8000,\"context_window\":64000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Fully
        open-source model \\u0026 technical report. Performance on par with OpenAI-o1.\"},{\"id\":\"deepseek/deepseek-chat\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":2.7e-7,\"caching_price\":2.7e-7,\"cached_price\":7e-8,\"output_price\":0.0000011,\"max_output_tokens\":8000,\"context_window\":64000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-V3
        achieves a significant breakthrough in inference speed over previous models.\\n\\nIt
        tops the leaderboard among open-source models and rivals the most advanced
        closed-source models globally.\"},{\"id\":\"coding/gemini-2.5-flash@us-central1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-flash@europe-north1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-flash@europe-west4\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-pro@us-central1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-pro\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-pro@us-east5\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/claude-4-sonnet\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Sonnet 4 significantly improves on Sonnet 3.7's industry-leading capabilities,
        excelling in coding with a state-of-the-art 72.7% on SWE-bench. The model
        balances performance and efficiency for internal and external use cases, with
        enhanced steerability for greater control over implementations.\"},{\"id\":\"coding/gemini-2.5-flash@us-south1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-pro@europe-north1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-flash\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-flash@us-east1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-flash@europe-west8\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-pro-preview-03-25\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-pro@us-east1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-pro@europe-central2\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/claude-4-opus\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"coding/gemini-2.5-pro@us-south1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-pro@us-west1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-pro@europe-west8\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-flash-preview-05-20\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":1.5e-7,\"caching_price\":4e-7,\"cached_price\":1.5e-7,\"output_price\":6e-7,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"coding/gemini-2.5-flash@us-east5\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-flash@us-west1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-flash@europe-central2\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/claude-3-7-sonnet\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"coding/gemini-2.5-pro-preview-05-06\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-flash@europe-west1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-pro@europe-west1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-pro@europe-west4\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"novita/microsoft/wizardlm-2-8x22b\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":6.2e-7,\"caching_price\":6.2e-7,\"cached_price\":6.2e-7,\"output_price\":6.2e-7,\"max_output_tokens\":0,\"context_window\":65535,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"WizardLM-2
        8x22B is Microsoft AI's most advanced Wizard model. It demonstrates highly
        competitive performance compared to leading proprietary models, and it consistently
        outperforms all existing state-of-the-art opensource models.\"},{\"id\":\"novita/nousresearch/hermes-2-pro-llama-3-8b\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":1.4e-7,\"caching_price\":1.4e-7,\"cached_price\":1.4e-7,\"output_price\":1.4e-7,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Hermes
        2 Pro is an upgraded, retrained version of Nous Hermes 2, consisting of an
        updated and cleaned version of the OpenHermes 2.5 Dataset, as well as a newly
        introduced Function Calling and JSON Mode dataset developed in-house.\"},{\"id\":\"novita/meta-llama/llama-3-8b-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":4e-8,\"caching_price\":4e-8,\"cached_price\":4e-8,\"output_price\":4e-8,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Meta's
        latest class of model (Llama 3) launched with a variety of sizes \\u0026 flavors.
        This 8B instruct-tuned version was optimized for high quality dialogue usecases.
        It has demonstrated strong performance compared to leading closed-source models
        in human evaluations.\"},{\"id\":\"novita/deepseek/deepseek-v3-turbo\",\"object\":\"model\",\"created\":1748631837,\"owned_by\":\"system\",\"input_price\":4e-7,\"caching_price\":4e-7,\"cached_price\":4e-7,\"output_price\":0.0000013,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek
        R1 is the latest open-source model released by the DeepSeek team, featuring
        impressive reasoning capabilities, particularly achieving performance comparable
        to OpenAI's o1 model in mathematics, coding, and reasoning tasks.\"},{\"id\":\"novita/gryphe/mythomax-l2-13b\",\"object\":\"model\",\"created\":1688259600,\"owned_by\":\"system\",\"input_price\":9e-8,\"caching_price\":9e-8,\"cached_price\":9e-8,\"output_price\":9e-8,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        idea behind this merge is that each layer is composed of several tensors,
        which are in turn responsible for specific functions. Using MythoLogic-L2's
        robust understanding as its input and Huginn's extensive writing capability
        as its output seems to have resulted in a model that exceeds at both, confirming
        my theory. (More details to be released at a later time).\"},{\"id\":\"novita/jondurbin/airoboros-l2-70b\",\"object\":\"model\",\"created\":1721222877,\"owned_by\":\"system\",\"input_price\":5e-7,\"caching_price\":5e-7,\"cached_price\":5e-7,\"output_price\":5e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"This
        is a fine-tuned Llama-2 model designed to support longer and more detailed
        writing prompts, as well as next-chapter generation. It also includes an experimental
        role-playing instruction set with multi-round dialogues, character interactions,
        and varying numbers of participants\"},{\"id\":\"novita/meta-llama/llama-3-70b-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":5.1e-7,\"caching_price\":5.1e-7,\"cached_price\":5.1e-7,\"output_price\":7.4e-7,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Meta's
        latest class of model (Llama 3) launched with a variety of sizes \\u0026 flavors.
        This 70B instruct-tuned version was optimized for high quality dialogue usecases.
        It has demonstrated strong performance compared to leading closed-source models
        in human evaluations.\"},{\"id\":\"novita/qwen/qwen-2.5-72b-instruct\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":3.8e-7,\"caching_price\":3.8e-7,\"cached_price\":3.8e-7,\"output_price\":4e-7,\"max_output_tokens\":0,\"context_window\":32000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen2.5
        is the latest series of Qwen large language models. For Qwen2.5, we release
        a number of base language models and instruction-tuned language models ranging
        from 0.5 to 72 billion parameters.\"},{\"id\":\"novita/meta-llama/llama-4-maverick-17b-128e-instruct-fp8\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":2e-7,\"caching_price\":2e-7,\"cached_price\":2e-7,\"output_price\":8.5e-7,\"max_output_tokens\":1048576,\"context_window\":1048576,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"novita/mistralai/mistral-7b-instruct\",\"object\":\"model\",\"created\":1718037161,\"owned_by\":\"system\",\"input_price\":5.9e-8,\"caching_price\":5.9e-8,\"cached_price\":5.9e-8,\"output_price\":5.9e-8,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        high-performing, industry-standard 7.3B parameter model, with optimizations
        for speed and context length.\"},{\"id\":\"novita/mistralai/mistral-nemo\",\"object\":\"model\",\"created\":1718037161,\"owned_by\":\"system\",\"input_price\":1.7e-7,\"caching_price\":1.7e-7,\"cached_price\":1.7e-7,\"output_price\":1.7e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        12B parameter model with a 128k token context length built by Mistral in collaboration
        with NVIDIA. The model is multilingual, supporting English, French, German,
        Spanish, Italian, Portuguese, Chinese, Japanese, Korean, Arabic, and Hindi.
        It supports function calling and is released under the Apache 2.0 license.\"},{\"id\":\"novita/deepseek/deepseek-r1-distill-llama-70b\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":8e-7,\"cached_price\":8e-7,\"output_price\":8e-7,\"max_output_tokens\":0,\"context_window\":32000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek
        R1 Distill LLama 70B\"},{\"id\":\"novita/sao10k/l3-8b-lunaris\",\"object\":\"model\",\"created\":1734535928,\"owned_by\":\"system\",\"input_price\":5e-8,\"caching_price\":5e-8,\"cached_price\":5e-8,\"output_price\":5e-8,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        generalist / roleplaying model merge based on Llama 3.\"},{\"id\":\"novita/deepseek/deepseek-v3-0324\",\"object\":\"model\",\"created\":1748631837,\"owned_by\":\"system\",\"input_price\":4e-7,\"caching_price\":4e-7,\"cached_price\":4e-7,\"output_price\":0.0000013,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek
        R1 is the latest open-source model released by the DeepSeek team, featuring
        impressive reasoning capabilities, particularly achieving performance comparable
        to OpenAI's o1 model in mathematics, coding, and reasoning tasks.\"},{\"id\":\"novita/deepseek/deepseek-r1\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":0.000004,\"caching_price\":0.000004,\"cached_price\":0.000004,\"output_price\":0.000004,\"max_output_tokens\":0,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek
        R1 is the latest open-source model released by the DeepSeek team, featuring
        impressive reasoning capabilities, particularly achieving performance comparable
        to OpenAI's o1 model in mathematics, coding, and reasoning tasks.\"},{\"id\":\"novita/sophosympatheia/midnight-rose-70b\",\"object\":\"model\",\"created\":1711065600,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":8e-7,\"cached_price\":8e-7,\"output_price\":8e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        merge with a complex family tree, this model was crafted for roleplaying and
        storytelling. Midnight Rose is a successor to Rogue Rose and Aurora Nights
        and improves upon them both. It wants to produce lengthy output by default
        and is the best creative writing merge produced so far by sophosympatheia.\"},{\"id\":\"novita/qwen/qwen-2-vl-72b-instruct\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":4.5e-7,\"caching_price\":4.5e-7,\"cached_price\":4.5e-7,\"output_price\":4.5e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen2
        VL 72B is a multimodal LLM from the Qwen Team with the following key enhancements:\\n\\nSoTA
        understanding of images of various resolution \\u0026 ratio: Qwen2-VL achieves
        state-of-the-art performance on visual understanding benchmarks, including
        MathVista, DocVQA, RealWorldQA, MTVQA, etc.\\n\\nUnderstanding videos of 20min+:
        Qwen2-VL can understand videos over 20 minutes for high-quality video-based
        question answering, dialog, content creation, etc.\\n\\nAgent that can operate
        your mobiles, robots, etc.: with the abilities of complex reasoning and decision
        making, Qwen2-VL can be integrated with devices like mobile phones, robots,
        etc., for automatic operation based on visual environment and text instructions.\\n\\nMultilingual
        Support: to serve global users, besides English and Chinese, Qwen2-VL now
        supports the understanding of texts in different languages inside images,
        including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.\"},{\"id\":\"novita/deepseek/deepseek-prover-v2-671b\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":7e-7,\"caching_price\":7e-7,\"cached_price\":7e-7,\"output_price\":0.0000025,\"max_output_tokens\":0,\"context_window\":160000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"novita/meta-llama/llama-3.3-70b-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":3.9e-7,\"caching_price\":3.9e-7,\"cached_price\":3.9e-7,\"output_price\":3.9e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and
        instruction tuned generative model in 70B (text in/text out). The Llama 3.3
        instruction tuned text only model is optimized for multilingual dialogue use
        cases and outperforms many of the available open source and closed chat models
        on common industry benchmarks.\\n\\nSupported languages: English, German,
        French, Italian, Portuguese, Hindi, Spanish, and Thai.\"},{\"id\":\"novita/Sao10K/L3-8B-Stheno-v3.2\",\"object\":\"model\",\"created\":1734535928,\"owned_by\":\"system\",\"input_price\":5e-8,\"caching_price\":5e-8,\"cached_price\":5e-8,\"output_price\":5e-8,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Sao10K/L3-8B-Stheno-v3.2
        is a highly skilled actor that excels at fully immersing itself in any role
        assigned.\"},{\"id\":\"novita/meta-llama/llama-3.2-3b-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":3e-8,\"caching_price\":3e-8,\"cached_price\":3e-8,\"output_price\":5e-8,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        Meta Llama 3.2 collection of multilingual large language models (LLMs) is
        a collection of pretrained and instruction-tuned generative models in 1B and
        3B sizes (text in/text out)\"},{\"id\":\"novita/sao10k/l3-70b-euryale-v2.1\",\"object\":\"model\",\"created\":1734535928,\"owned_by\":\"system\",\"input_price\":0.00000148,\"caching_price\":0.00000148,\"cached_price\":0.00000148,\"output_price\":0.00000148,\"max_output_tokens\":0,\"context_window\":16000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        uncensored llama3 model is a powerhouse of creativity, excelling in both roleplay
        and story writing. It offers a liberating experience during roleplays, free
        from any restrictions. This model stands out for its immense creativity, boasting
        a vast array of unique ideas and plots, truly a treasure trove for those seeking
        originality. Its unrestricted nature during roleplays allows for the full
        breadth of imagination to unfold, akin to an enhanced, big-brained version
        of Stheno. Perfect for creative minds seeking a boundless platform for their
        imaginative expressions, the uncensored llama3 model is an ideal choice\"},{\"id\":\"novita/deepseek/deepseek-r1-distill-qwen-14b\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":1.5e-7,\"caching_price\":1.5e-7,\"cached_price\":1.5e-7,\"output_price\":1.5e-7,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek
        R1 Distill Qwen 14B is a distilled large language model based on Qwen 2.5
        14B, using outputs from DeepSeek R1. It outperforms OpenAI's o1-mini across
        various benchmarks, achieving new state-of-the-art results for dense models.\\n\\nOther
        benchmark results include:\\n\\nAIME 2024 pass@1: 69.7\\nMATH-500 pass@1:
        93.9\\nCodeForces Rating: 1481\\nThe model leverages fine-tuning from DeepSeek
        R1's outputs, enabling competitive performance comparable to larger frontier
        models.\"},{\"id\":\"novita/meta-llama/llama-3.1-8b-instruct-bf16\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":6e-8,\"caching_price\":6e-8,\"cached_price\":6e-8,\"output_price\":6e-8,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Meta's
        latest class of models, Llama 3.1, launched with a variety of sizes and configurations.
        The 8B instruct-tuned version is particularly fast and efficient. It has demonstrated
        strong performance in human evaluations, \\n                   outperforming
        several leading closed-source models.\"},{\"id\":\"novita/deepseek/deepseek_v3\",\"object\":\"model\",\"created\":1748631837,\"owned_by\":\"system\",\"input_price\":8.9e-7,\"caching_price\":8.9e-7,\"cached_price\":8.9e-7,\"output_price\":8.9e-7,\"max_output_tokens\":0,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-V3
        is the latest model from the DeepSeek team, building upon the instruction
        following and coding abilities of the previous versions. Pre-trained on nearly
        15 trillion tokens, the reported evaluations reveal that the model outperforms
        other open-source models and rivals leading closed-source models.\"},{\"id\":\"novita/qwen/qwq-32b\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":1.8e-7,\"caching_price\":1.8e-7,\"cached_price\":1.8e-7,\"output_price\":2e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"novita/qwen/qwen-2-7b-instruct\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":5.4e-8,\"caching_price\":5.4e-8,\"cached_price\":5.4e-8,\"output_price\":5.4e-8,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen2
        is the newest series in the Qwen large language model family. Qwen2 7B is
        a transformer-based model that demonstrates exceptional performance in language
        understanding, multilingual capabilities, programming, mathematics, and reasoning.\"},{\"id\":\"novita/qwen/qwen2.5-vl-72b-instruct\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":8e-7,\"cached_price\":8e-7,\"output_price\":8e-7,\"max_output_tokens\":0,\"context_window\":96000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen2
        VL 72B is a multimodal LLM from the Qwen Team with the following key enhancements:\\n\\nSoTA
        understanding of images of various resolution \\u0026 ratio: Qwen2-VL achieves
        state-of-the-art performance on visual understanding benchmarks, including
        MathVista, DocVQA, RealWorldQA, MTVQA, etc.\\n\\nUnderstanding videos of 20min+:
        Qwen2-VL can understand videos over 20 minutes for high-quality video-based
        question answering, dialog, content creation, etc.\\n\\nAgent that can operate
        your mobiles, robots, etc.: with the abilities of complex reasoning and decision
        making, Qwen2-VL can be integrated with devices like mobile phones, robots,
        etc., for automatic operation based on visual environment and text instructions.\\n\\nMultilingual
        Support: to serve global users, besides English and Chinese, Qwen2-VL now
        supports the understanding of texts in different languages inside images,
        including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.\"},{\"id\":\"novita/meta-llama/llama-3.1-8b-instruct-max\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":5e-8,\"caching_price\":5e-8,\"cached_price\":5e-8,\"output_price\":5e-8,\"max_output_tokens\":0,\"context_window\":16384,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Meta's
        latest class of models, Llama 3.1, launched with a variety of sizes and configurations.
        The 8B instruct-tuned version is particularly fast and efficient. It has demonstrated
        strong performance in human evaluations, outperforming several leading closed-source
        models.\"},{\"id\":\"novita/google/gemma-2-9b-it\",\"object\":\"model\",\"created\":1721318624,\"owned_by\":\"system\",\"input_price\":8e-8,\"caching_price\":8e-8,\"cached_price\":8e-8,\"output_price\":8e-8,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Gemma
        2 9B by Google is an advanced, open-source language model that sets a new
        standard for efficiency and performance in its size class.\\nDesigned for
        a wide variety of tasks, it empowers developers and researchers to build innovative
        applications, while maintaining accessibility, safety, and cost-effectiveness.\"},{\"id\":\"novita/nousresearch/nous-hermes-llama2-13b\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":1.7e-7,\"caching_price\":1.7e-7,\"cached_price\":1.7e-7,\"output_price\":1.7e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Nous-Hermes-Llama2-13b
        is a state-of-the-art language model fine-tuned on over 300,000 instructions.
        This model was fine-tuned by Nous Research, with Teknium and Emozilla leading
        the fine tuning process and dataset curation, Redmond AI sponsoring the compute,
        and several other contributors.\"},{\"id\":\"novita/meta-llama/llama-3.1-70b-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":3.4e-7,\"caching_price\":3.4e-7,\"cached_price\":3.4e-7,\"output_price\":3.9e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Meta's
        latest class of models, Llama 3.1, has launched with a variety of sizes and
        configurations. The 70B instruct-tuned version is optimized for high-quality
        dialogue use cases. It has demonstrated strong performance in human evaluations
        compared to leading closed-source models.\"},{\"id\":\"novita/qwen/qwen3-235b-a22b-fp8\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":2e-7,\"caching_price\":2e-7,\"cached_price\":2e-7,\"output_price\":8e-7,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"novita/sao10k/l31-70b-euryale-v2.2\",\"object\":\"model\",\"created\":1734535928,\"owned_by\":\"system\",\"input_price\":0.00000148,\"caching_price\":0.00000148,\"cached_price\":0.00000148,\"output_price\":0.00000148,\"max_output_tokens\":0,\"context_window\":16000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Euryale
        L3.1 70B v2.2 is a model focused on creative roleplay from Sao10k. It is the
        successor of Euryale L3 70B v2.1.\"},{\"id\":\"novita/deepseek/deepseek-r1-distill-qwen-32b\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":3e-7,\"cached_price\":3e-7,\"output_price\":3e-7,\"max_output_tokens\":0,\"context_window\":12800,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek
        R1 Distill Qwen 32B is a distilled large language model based on Qwen 2.5
        32B, using outputs from DeepSeek R1. It outperforms OpenAI's o1-mini across
        various benchmarks, achieving new state-of-the-art results for dense models.\\n\\nOther
        benchmark results include:\\nAIME 2024 pass@1: 72.6\\nMATH-500 pass@1: 94.3\\nCodeForces
        Rating: 1691\\nThe model leverages fine-tuning from DeepSeek R1's outputs,
        enabling competitive performance comparable to larger frontier models.\"},{\"id\":\"novita/deepseek/deepseek-r1-turbo\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":7e-7,\"caching_price\":0.0000025,\"cached_price\":7e-7,\"output_price\":0.0000025,\"max_output_tokens\":0,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek
        R1 is the latest open-source model released by the DeepSeek team, featuring
        impressive reasoning capabilities, particularly achieving performance comparable
        to OpenAI's o1 model in mathematics, coding, and reasoning tasks.\"},{\"id\":\"novita/meta-llama/llama-3.2-1b-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":2e-8,\"caching_price\":2e-8,\"cached_price\":2e-8,\"output_price\":2e-8,\"max_output_tokens\":0,\"context_window\":131000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        Meta Llama 3.2 collection of multilingual large language models (LLMs) is
        a collection of pretrained and instruction-tuned generative models in 1B and
        3B sizes (text in/text out).\"},{\"id\":\"novita/openchat/openchat-7b\",\"object\":\"model\",\"created\":1721999372,\"owned_by\":\"system\",\"input_price\":6e-8,\"caching_price\":6e-8,\"cached_price\":6e-8,\"output_price\":6e-8,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"OpenChat
        7B is a library of open-source language models, fine-tuned with \\\"C-RLFT
        (Conditioned Reinforcement Learning Fine-Tuning)\\\" - a strategy inspired
        by offline reinforcement learning. It has been trained on mixed-quality data
        without preference labels.\"},{\"id\":\"novita/meta-llama/llama-3.1-8b-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":5e-8,\"caching_price\":5e-8,\"cached_price\":5e-8,\"output_price\":5e-8,\"max_output_tokens\":0,\"context_window\":16384,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Meta's
        latest class of models, Llama 3.1, launched with a variety of sizes and configurations.
        The 8B instruct-tuned version is particularly fast and efficient. It has demonstrated
        strong performance in human evaluations, outperforming several leading closed-source
        models.\"},{\"id\":\"novita/meta-llama/llama-3.2-11b-vision-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":6e-8,\"caching_price\":6e-8,\"cached_price\":6e-8,\"output_price\":6e-8,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Llama
        3.2 11B Vision is a multimodal model with 11 billion parameters, designed
        to handle tasks combining visual and textual data. It excels in tasks such
        as image captioning and visual question answering, bridging the gap between
        language generation and visual reasoning. Pre-trained on a massive dataset
        of image-text pairs, it performs well in complex, high-accuracy image analysis.
        Its ability to integrate visual understanding with language processing makes
        it an ideal solution for industries requiring comprehensive visual-linguistic
        AI applications, such as content creation, AI-driven customer service, and
        research.\"},{\"id\":\"novita/teknium/openhermes-2.5-mistral-7b\",\"object\":\"model\",\"created\":1713945673,\"owned_by\":\"system\",\"input_price\":1.7e-7,\"caching_price\":1.7e-7,\"cached_price\":1.7e-7,\"output_price\":1.7e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"OpenHermes
        2.5 Mistral 7B is a state of the art Mistral Fine-tune, a continuation of
        OpenHermes 2 model, which trained on additional code datasets.\"},{\"id\":\"nebius/meta-llama/Llama-3.3-70B-Instruct\",\"object\":\"model\",\"created\":1715697754,\"owned_by\":\"system\",\"input_price\":1.3e-7,\"caching_price\":1.3e-7,\"cached_price\":1.3e-7,\"output_price\":4e-7,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"nebius/deepseek-ai/DeepSeek-V3\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":5e-7,\"caching_price\":5e-7,\"cached_price\":5e-7,\"output_price\":0.0000015,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"nebius/deepseek-ai/DeepSeek-R1\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":8e-7,\"cached_price\":8e-7,\"output_price\":0.0000024,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"nebius/deepseek-ai/DeepSeek-V3-0324\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":5e-7,\"caching_price\":5e-7,\"cached_price\":5e-7,\"output_price\":0.0000015,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"nebius/deepseek-ai/DeepSeek-R1-0528\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":8e-7,\"cached_price\":8e-7,\"output_price\":0.0000024,\"max_output_tokens\":0,\"context_window\":164000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"nebius/deepseek-ai/DeepSeek-V3-0324-fast\",\"object\":\"model\",\"created\":1748631837,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000006,\"cached_price\":0.000002,\"output_price\":0.000006,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"nebius/deepseek-ai/DeepSeek-R1-fast\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":0.000002,\"output_price\":0.000006,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"nebius/Qwen/QwQ-32B-fast\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":5e-7,\"caching_price\":5e-7,\"cached_price\":5e-7,\"output_price\":0.0000015,\"max_output_tokens\":0,\"context_window\":32000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"nebius/Qwen/QwQ-32B\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":1.5e-7,\"caching_price\":1.5e-7,\"cached_price\":1.5e-7,\"output_price\":4.5e-7,\"max_output_tokens\":0,\"context_window\":32000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"groq/qwen-qwq-32b\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":2.9e-7,\"caching_price\":2.9e-7,\"cached_price\":2.9e-7,\"output_price\":3.9e-7,\"max_output_tokens\":131072,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen/QwQ-32B
        is a breakthrough 32-billion parameter reasoning model delivering performance
        comparable to state-of-the-art (SOTA) models 20x larger like DeepSeek-R1 (671B
        parameters) on complex reasoning and coding tasks. Deployed on Groq's hardware,
        it provides the world's fastest and cost-efficient reasoning, producing chains
        and results in seconds. Along with native tool use support, the 128K context
        window enables processing extensive information while maintaining comprehensive
        context.\"}]}\n"
    headers:
      content-length:
      - '228652'
      content-type:
      - application/json
      date:
      - Fri, 11 Jul 2025 00:02:11 GMT
      fly-request-id:
      - 01JZVCM8AYRM4W46TYVK0MAQ8P-sea
      server:
      - Fly/a608e03f9 (2025-07-10)
      transfer-encoding:
      - chunked
      vary:
      - Origin
      via:
      - 1.1 fly.io, 1.1 fly.io
    status:
      code: 200
      message: OK
- request:
    body: ''
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      host:
      - router.requesty.ai
      user-agent:
      - python-httpx/0.28.1
    method: GET
    uri: https://router.requesty.ai/v1/models?supported_parameters=structured_outputs
  response:
    body:
      string: "{\"object\":\"list\",\"data\":[{\"id\":\"xai/grok-3-mini-fast-beta:high\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":6e-7,\"caching_price\":6e-7,\"cached_price\":6e-7,\"output_price\":0.000004,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"xai/grok-3-mini-fast-beta\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":6e-7,\"caching_price\":6e-7,\"cached_price\":6e-7,\"output_price\":0.000004,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"xai/grok-2-1212\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":0.000002,\"output_price\":0.00001,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"xai/grok-3-beta\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.000003,\"cached_price\":0.000003,\"output_price\":0.000015,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"xai/grok-2-latest\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":0.000002,\"output_price\":0.00001,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"xai/grok-4\",\"object\":\"model\",\"created\":1752171508,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.000003,\"cached_price\":7.5e-7,\"output_price\":0.000015,\"max_output_tokens\":0,\"context_window\":256000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"xai/grok-3-mini-beta:low\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":3e-7,\"cached_price\":3e-7,\"output_price\":5e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"xai/grok-3-mini-beta:high\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":3e-7,\"cached_price\":3e-7,\"output_price\":5e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"xai/grok-3-fast-beta\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":0.000005,\"caching_price\":0.000005,\"cached_price\":0.000005,\"output_price\":0.000025,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"xai/grok-3-mini-fast-beta:low\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":6e-7,\"caching_price\":6e-7,\"cached_price\":6e-7,\"output_price\":0.000004,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"xai/grok-3-mini-beta\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":3e-7,\"cached_price\":3e-7,\"output_price\":5e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"openai/o3\",\"object\":\"model\",\"created\":1744827057,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":5e-7,\"output_price\":0.000008,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023.\"},{\"id\":\"openai/o3-mini-2025-01-31\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/gpt-4.1-nano\",\"object\":\"model\",\"created\":1744654969,\"owned_by\":\"system\",\"input_price\":1e-7,\"caching_price\":1e-7,\"cached_price\":2.5e-8,\"output_price\":4e-7,\"max_output_tokens\":32768,\"context_window\":1047576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"For
        tasks that demand low latency, GPT\u20114.1 nano is the fastest and cheapest
        model in the GPT-4.1 series. It delivers exceptional performance at a small
        size with its 1 million token context window, and scores 80.1% on MMLU, 50.3%
        on GPQA, and 9.8% on Aider polyglot coding \u2013 even higher than GPT\u20114o
        mini. It\u2019s ideal for tasks like classification or autocompletion.\"},{\"id\":\"openai/gpt-4.1\",\"object\":\"model\",\"created\":1744654985,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":5e-7,\"output_price\":0.000008,\"max_output_tokens\":32768,\"context_window\":1047576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"GPT-4.1
        is a flagship large language model optimized for advanced instruction following,
        real-world software engineering, and long-context reasoning. It supports a
        1 million token context window and outperforms GPT-4o and GPT-4.5 across coding
        (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal
        understanding benchmarks. It is tuned for precise code diffs, agent reliability,
        and high recall in large document contexts, making it ideal for agents, IDE
        tooling, and enterprise knowledge retrieval.\"},{\"id\":\"openai/o4-mini-2025-04-16\",\"object\":\"model\",\"created\":1744824542,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":2.75e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/o1-mini\",\"object\":\"model\",\"created\":1726102800,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":65536,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023. o1-mini is a faster and more affordable reasoning
        model, but OpenAI recommends using the newer o3-mini model that features higher
        intelligence at the same latency and price as o1-mini.\"},{\"id\":\"openai/o1:low\",\"object\":\"model\",\"created\":1734459999,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.000015,\"cached_price\":0.0000075,\"output_price\":0.00006,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023.\"},{\"id\":\"openai/o1:high\",\"object\":\"model\",\"created\":1734459999,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.000015,\"cached_price\":0.0000075,\"output_price\":0.00006,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023.\"},{\"id\":\"openai/gpt-4.1-2025-04-14\",\"object\":\"model\",\"created\":1744654985,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":5e-7,\"output_price\":0.000008,\"max_output_tokens\":32768,\"context_window\":1047576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"GPT-4.1
        is a flagship large language model optimized for advanced instruction following,
        real-world software engineering, and long-context reasoning. It supports a
        1 million token context window and outperforms GPT-4o and GPT-4.5 across coding
        (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal
        understanding benchmarks. It is tuned for precise code diffs, agent reliability,
        and high recall in large document contexts, making it ideal for agents, IDE
        tooling, and enterprise knowledge retrieval.\"},{\"id\":\"openai/o3-mini:low\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/gpt-4o-2024-11-20\",\"object\":\"model\",\"created\":1732127594,\"owned_by\":\"system\",\"input_price\":0.0000025,\"caching_price\":0.0000025,\"cached_price\":0.00000125,\"output_price\":0.00001,\"max_output_tokens\":16384,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        2024-11-20 version of GPT-4o offers a leveled-up creative writing ability
        with more natural, engaging, and tailored writing to improve relevance \\u0026
        readability. It\u2019s also better at working with uploaded files, providing
        deeper insights \\u0026 more thorough responses.\\n\\nGPT-4o (\\\"o\\\" for
        \\\"omni\\\") is OpenAI's latest AI model, supporting both text and image
        inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo)
        while being twice as fast and 50% more cost-effective. GPT-4o also offers
        improved performance in processing non-English languages and enhanced visual
        capabilities.\"},{\"id\":\"openai/o4-mini:low\",\"object\":\"model\",\"created\":1744824542,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":2.75e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/gpt-4.5-preview\",\"object\":\"model\",\"created\":1740687810,\"owned_by\":\"system\",\"input_price\":0.000075,\"caching_price\":0.000075,\"cached_price\":0.0000375,\"output_price\":0.00015,\"max_output_tokens\":4096,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"GPT-4.5
        (Preview) is a research preview of OpenAI\u2019s latest language model, designed
        to advance capabilities in reasoning, creativity, and multi-turn conversation.
        It builds on previous iterations with improvements in world knowledge, contextual
        coherence, and the ability to follow user intent more effectively.\\n\\nThe
        model demonstrates enhanced performance in tasks that require open-ended thinking,
        problem-solving, and communication. Early testing suggests it is better at
        generating nuanced responses, maintaining long-context coherence, and reducing
        hallucinations compared to earlier versions.\\n\\nThis research preview is
        intended to help evaluate GPT-4.5\u2019s strengths and limitations in real-world
        use cases as OpenAI continues to refine and develop future models. Read more
        at the [blog post here.](https://openai.com/index/introducing-gpt-4-5/)\"},{\"id\":\"openai/o3-2025-04-16\",\"object\":\"model\",\"created\":1744827057,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":5e-7,\"output_price\":0.000008,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023.\"},{\"id\":\"openai/o1-2024-12-17\",\"object\":\"model\",\"created\":1734459999,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.000015,\"cached_price\":0.0000075,\"output_price\":0.00006,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023.\"},{\"id\":\"openai/o3:flex\",\"object\":\"model\",\"created\":1744827057,\"owned_by\":\"system\",\"input_price\":0.000001,\"caching_price\":0.000001,\"cached_price\":2.5e-7,\"output_price\":0.000004,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"O3
        Flex is a cheaper version of the o3 model\"},{\"id\":\"openai/gpt-4o-mini-2024-07-18\",\"object\":\"model\",\"created\":1721264400,\"owned_by\":\"system\",\"input_price\":1.5e-7,\"caching_price\":1.5e-7,\"cached_price\":7.5e-8,\"output_price\":6e-7,\"max_output_tokens\":16384,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"GPT-4o
        mini is OpenAI's newest model after [GPT-4 Omni](/models/openai/gpt-4o), supporting
        both text and image inputs with text outputs.\\n\\nAs their most advanced
        small model, it is many multiples more affordable than other recent frontier
        models, and more than 60% cheaper than [GPT-3.5 Turbo](/models/openai/gpt-3.5-turbo).
        It maintains SOTA intelligence, while being significantly more cost-effective.\\n\\nGPT-4o
        mini achieves an 82% score on MMLU and presently ranks higher than GPT-4 on
        chat preferences [common leaderboards](https://arena.lmsys.org/).\\n\\nCheck
        out the [launch announcement](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)
        to learn more.\\n\\n#multimodal\"},{\"id\":\"openai/chatgpt-4o-latest\",\"object\":\"model\",\"created\":1723597200,\"owned_by\":\"system\",\"input_price\":0.000005,\"caching_price\":0.000005,\"cached_price\":0.000005,\"output_price\":0.000015,\"max_output_tokens\":16000,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"OpenAI
        ChatGPT 4o is continually updated by OpenAI to point to the current version
        of GPT-4o used by ChatGPT. It therefore differs slightly from the API version
        of [GPT-4o](/models/openai/gpt-4o) in that it has additional RLHF. It is intended
        for research and evaluation.\\n\\nOpenAI notes that this model is not suited
        for production use-cases as it may be removed or redirected to another model
        in the future.\"},{\"id\":\"openai/gpt-4.1-mini-2025-04-14\",\"object\":\"model\",\"created\":1744654981,\"owned_by\":\"system\",\"input_price\":4e-7,\"caching_price\":4e-7,\"cached_price\":1e-7,\"output_price\":0.0000016,\"max_output_tokens\":32768,\"context_window\":1047576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"GPT-4.1
        Mini is a mid-sized model delivering performance competitive with GPT-4o at
        substantially lower latency and cost. It retains a 1 million token context
        window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge,
        and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on
        Aider\u2019s polyglot diff benchmark) and vision understanding, making it
        suitable for interactive applications with tight performance constraints.\"},{\"id\":\"openai/o1\",\"object\":\"model\",\"created\":1734459999,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.000015,\"cached_price\":0.0000075,\"output_price\":0.00006,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023.\"},{\"id\":\"openai/o3-mini\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/o3-mini:high\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/o3-pro\",\"object\":\"model\",\"created\":1749601952,\"owned_by\":\"system\",\"input_price\":0.00002,\"caching_price\":0.00002,\"cached_price\":0.00002,\"output_price\":0.00008,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":false,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o3 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023.\"},{\"id\":\"openai/gpt-4o-2024-05-13\",\"object\":\"model\",\"created\":1732127594,\"owned_by\":\"system\",\"input_price\":0.0000025,\"caching_price\":0.0000025,\"cached_price\":0.0000025,\"output_price\":0.00001,\"max_output_tokens\":4096,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        2024-11-20 version of GPT-4o offers a leveled-up creative writing ability
        with more natural, engaging, and tailored writing to improve relevance \\u0026
        readability. It\u2019s also better at working with uploaded files, providing
        deeper insights \\u0026 more thorough responses.\\n\\nGPT-4o (\\\"o\\\" for
        \\\"omni\\\") is OpenAI's latest AI model, supporting both text and image
        inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo)
        while being twice as fast and 50% more cost-effective. GPT-4o also offers
        improved performance in processing non-English languages and enhanced visual
        capabilities.\"},{\"id\":\"openai/gpt-4o-2024-08-06\",\"object\":\"model\",\"created\":1732127594,\"owned_by\":\"system\",\"input_price\":0.0000025,\"caching_price\":0.0000025,\"cached_price\":0.00000125,\"output_price\":0.00001,\"max_output_tokens\":16384,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        2024-11-20 version of GPT-4o offers a leveled-up creative writing ability
        with more natural, engaging, and tailored writing to improve relevance \\u0026
        readability. It\u2019s also better at working with uploaded files, providing
        deeper insights \\u0026 more thorough responses.\\n\\nGPT-4o (\\\"o\\\" for
        \\\"omni\\\") is OpenAI's latest AI model, supporting both text and image
        inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo)
        while being twice as fast and 50% more cost-effective. GPT-4o also offers
        improved performance in processing non-English languages and enhanced visual
        capabilities.\"},{\"id\":\"openai/gpt-4o-mini\",\"object\":\"model\",\"created\":1721264400,\"owned_by\":\"system\",\"input_price\":1.5e-7,\"caching_price\":1.5e-7,\"cached_price\":7.5e-8,\"output_price\":6e-7,\"max_output_tokens\":16384,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"GPT-4o
        mini is OpenAI's newest model after [GPT-4 Omni](/models/openai/gpt-4o), supporting
        both text and image inputs with text outputs.\\n\\nAs their most advanced
        small model, it is many multiples more affordable than other recent frontier
        models, and more than 60% cheaper than [GPT-3.5 Turbo](/models/openai/gpt-3.5-turbo).
        It maintains SOTA intelligence, while being significantly more cost-effective.\\n\\nGPT-4o
        mini achieves an 82% score on MMLU and presently ranks higher than GPT-4 on
        chat preferences [common leaderboards](https://arena.lmsys.org/).\\n\\nCheck
        out the [launch announcement](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)
        to learn more.\\n\\n#multimodal\"},{\"id\":\"openai/gpt-4.1-mini\",\"object\":\"model\",\"created\":1744654981,\"owned_by\":\"system\",\"input_price\":4e-7,\"caching_price\":4e-7,\"cached_price\":1e-7,\"output_price\":0.0000016,\"max_output_tokens\":32768,\"context_window\":1047576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"GPT-4.1
        Mini is a mid-sized model delivering performance competitive with GPT-4o at
        substantially lower latency and cost. It retains a 1 million token context
        window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge,
        and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on
        Aider\u2019s polyglot diff benchmark) and vision understanding, making it
        suitable for interactive applications with tight performance constraints.\"},{\"id\":\"openai/o1-mini-2024-09-12\",\"object\":\"model\",\"created\":1726102800,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":65536,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023. o1-mini is a faster and more affordable reasoning
        model, but OpenAI recommends using the newer o3-mini model that features higher
        intelligence at the same latency and price as o1-mini.\"},{\"id\":\"openai/gpt-4.1-nano-2025-04-14\",\"object\":\"model\",\"created\":1744654969,\"owned_by\":\"system\",\"input_price\":1e-7,\"caching_price\":1e-7,\"cached_price\":2.5e-8,\"output_price\":4e-7,\"max_output_tokens\":32768,\"context_window\":1047576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"For
        tasks that demand low latency, GPT\u20114.1 nano is the fastest and cheapest
        model in the GPT-4.1 series. It delivers exceptional performance at a small
        size with its 1 million token context window, and scores 80.1% on MMLU, 50.3%
        on GPQA, and 9.8% on Aider polyglot coding \u2013 even higher than GPT\u20114o
        mini. It\u2019s ideal for tasks like classification or autocompletion.\"},{\"id\":\"openai/o4-mini\",\"object\":\"model\",\"created\":1744824542,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":2.75e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/o1:medium\",\"object\":\"model\",\"created\":1734459999,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.000015,\"cached_price\":0.0000075,\"output_price\":0.00006,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"The
        o1 series of models are trained with reinforcement learning to perform complex
        reasoning. o1 models think before they answer, producing a long internal chain
        of thought before responding to the user. The o1 reasoning model is designed
        to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini
        models is October, 2023.\"},{\"id\":\"openai/o4-mini:flex\",\"object\":\"model\",\"created\":1744824542,\"owned_by\":\"system\",\"input_price\":5.5e-7,\"caching_price\":5.5e-7,\"cached_price\":1.38e-7,\"output_price\":0.0000022,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/o3-mini:medium\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/o4-mini:medium\",\"object\":\"model\",\"created\":1744824542,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":2.75e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/o4-mini:high\",\"object\":\"model\",\"created\":1744824542,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":2.75e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"o3-mini
        is OpenAI's most recent small reasoning model, providing high intelligence
        at the same cost and latency targets of o1-mini. o3-mini also supports key
        developer features, like Structured Outputs, function calling, Batch API,
        and more. Like other models in the o-series, it is designed to excel at science,
        math, and coding tasks.\"},{\"id\":\"openai/gpt-4o\",\"object\":\"model\",\"created\":1732127594,\"owned_by\":\"system\",\"input_price\":0.0000025,\"caching_price\":0.0000025,\"cached_price\":0.00000125,\"output_price\":0.00001,\"max_output_tokens\":16384,\"context_window\":128000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        2024-11-20 version of GPT-4o offers a leveled-up creative writing ability
        with more natural, engaging, and tailored writing to improve relevance \\u0026
        readability. It\u2019s also better at working with uploaded files, providing
        deeper insights \\u0026 more thorough responses.\\n\\nGPT-4o (\\\"o\\\" for
        \\\"omni\\\") is OpenAI's latest AI model, supporting both text and image
        inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo)
        while being twice as fast and 50% more cost-effective. GPT-4o also offers
        improved performance in processing non-English languages and enhanced visual
        capabilities.\"},{\"id\":\"deepseek/deepseek-reasoner\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":5.5e-7,\"caching_price\":5.5e-7,\"cached_price\":1.4e-7,\"output_price\":0.00000219,\"max_output_tokens\":8000,\"context_window\":64000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Fully
        open-source model \\u0026 technical report. Performance on par with OpenAI-o1.\"},{\"id\":\"deepseek/deepseek-chat\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":2.7e-7,\"caching_price\":2.7e-7,\"cached_price\":7e-8,\"output_price\":0.0000011,\"max_output_tokens\":8000,\"context_window\":64000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-V3
        achieves a significant breakthrough in inference speed over previous models.\\n\\nIt
        tops the leaderboard among open-source models and rivals the most advanced
        closed-source models globally.\"},{\"id\":\"nebius/deepseek-ai/DeepSeek-R1\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":8e-7,\"cached_price\":8e-7,\"output_price\":0.0000024,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"nebius/deepseek-ai/DeepSeek-R1-fast\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":0.000002,\"output_price\":0.000006,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"nebius/deepseek-ai/DeepSeek-V3-0324\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":5e-7,\"caching_price\":5e-7,\"cached_price\":5e-7,\"output_price\":0.0000015,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"nebius/Qwen/QwQ-32B-fast\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":5e-7,\"caching_price\":5e-7,\"cached_price\":5e-7,\"output_price\":0.0000015,\"max_output_tokens\":0,\"context_window\":32000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"nebius/deepseek-ai/DeepSeek-V3\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":5e-7,\"caching_price\":5e-7,\"cached_price\":5e-7,\"output_price\":0.0000015,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"nebius/deepseek-ai/DeepSeek-R1-0528\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":8e-7,\"cached_price\":8e-7,\"output_price\":0.0000024,\"max_output_tokens\":0,\"context_window\":164000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"nebius/deepseek-ai/DeepSeek-V3-0324-fast\",\"object\":\"model\",\"created\":1748631837,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000006,\"cached_price\":0.000002,\"output_price\":0.000006,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"nebius/meta-llama/Llama-3.3-70B-Instruct\",\"object\":\"model\",\"created\":1715697754,\"owned_by\":\"system\",\"input_price\":1.3e-7,\"caching_price\":1.3e-7,\"cached_price\":1.3e-7,\"output_price\":4e-7,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"nebius/Qwen/QwQ-32B\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":1.5e-7,\"caching_price\":1.5e-7,\"cached_price\":1.5e-7,\"output_price\":4.5e-7,\"max_output_tokens\":0,\"context_window\":32000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet-20241022@europe-west1\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"vertex/google/gemini-2.5-pro@us-west1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet-20250219\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet-latest@us-east5\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet-20241022\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"vertex/anthropic/claude-4-sonnet-latest@us-east5\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/google/gemini-2.5-pro@us-central1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/google/gemini-2.5-pro@us-south1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/google/gemini-2.5-pro@europe-west8\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/google/gemini-2.5-flash@us-east5\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-flash@europe-west1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-flash@europe-west8\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-pro\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/google/gemini-2.5-pro@us-east5\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/google/gemini-2.5-pro@europe-central2\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet-20250219@europe-west1\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet-latest@europe-west1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/google/gemini-2.5-flash@us-west1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-flash@europe-north1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-flash@europe-west4\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet@europe-west1\",\"object\":\"model\",\"created\":1729558800,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet-latest@us-east5\",\"object\":\"model\",\"created\":1729558800,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet@us-east5\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet-20241022@us-east5\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet-latest@europe-west1\",\"object\":\"model\",\"created\":1729558800,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"vertex/anthropic/claude-4-sonnet@europe-west1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/google/gemini-2.5-flash@europe-central2\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-pro@europe-north1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet-20250219@us-east5\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet-latest\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet@europe-west1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-4-sonnet-latest@europe-west1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-4-sonnet@us-east5\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/google/gemini-2.5-flash\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-pro@europe-west1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/google/gemini-2.5-flash@us-south1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-pro@us-east1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/google/gemini-2.5-pro@europe-west4\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet@us-east5\",\"object\":\"model\",\"created\":1729558800,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet-latest\",\"object\":\"model\",\"created\":1729558800,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"vertex/anthropic/claude-4-sonnet\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/google/gemini-2.5-flash@us-central1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/google/gemini-2.5-flash@us-east1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"vertex/anthropic/claude-4-sonnet-latest\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-3-7-sonnet\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"vertex/anthropic/claude-3-5-sonnet\",\"object\":\"model\",\"created\":1729558800,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"alibaba/qwen-turbo\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":5e-8,\"caching_price\":5e-8,\"cached_price\":5e-8,\"output_price\":2e-7,\"max_output_tokens\":0,\"context_window\":1000000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"alibaba/qwen-max\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":0.0000016,\"caching_price\":0.0000016,\"cached_price\":0.0000016,\"output_price\":0.0000064,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"alibaba/qwen-plus\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":4e-7,\"caching_price\":4e-7,\"cached_price\":4e-7,\"output_price\":0.0000012,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"groq/qwen-qwq-32b\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":2.9e-7,\"caching_price\":2.9e-7,\"cached_price\":2.9e-7,\"output_price\":3.9e-7,\"max_output_tokens\":131072,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen/QwQ-32B
        is a breakthrough 32-billion parameter reasoning model delivering performance
        comparable to state-of-the-art (SOTA) models 20x larger like DeepSeek-R1 (671B
        parameters) on complex reasoning and coding tasks. Deployed on Groq's hardware,
        it provides the world's fastest and cost-efficient reasoning, producing chains
        and results in seconds. Along with native tool use support, the 128K context
        window enables processing extensive information while maintaining comprehensive
        context.\"},{\"id\":\"together/meta-llama/Llama-3-70b-chat-hf\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8.8e-7,\"caching_price\":8.8e-7,\"cached_price\":8.8e-7,\"output_price\":8.8e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\",\"object\":\"model\",\"created\":1744123094,\"owned_by\":\"system\",\"input_price\":8.8e-7,\"caching_price\":8.8e-7,\"cached_price\":8.8e-7,\"output_price\":8.8e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Llama-3.3-Nemotron-Super-49B-v1
        is a large language model (LLM) optimized for advanced reasoning, conversational
        interactions, retrieval-augmented generation (RAG), and tool-calling tasks.
        Derived from Meta's Llama-3.3-70B-Instruct, it employs a Neural Architecture
        Search (NAS) approach, significantly enhancing efficiency and reducing memory
        requirements. This allows the model to support a context length of up to 128K
        tokens and fit efficiently on single high-performance GPUs, such as NVIDIA
        H200.\\n\\nNote: you must include `detailed thinking on` in the system prompt
        to enable reasoning. Please see [Usage Recommendations](https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1#quick-start-and-usage-recommendations)
        for more.\"},{\"id\":\"together/Qwen/Qwen2-72B-Instruct\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":9e-7,\"caching_price\":9e-7,\"cached_price\":9e-7,\"output_price\":9e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"together/meta-llama/Meta-Llama-3-70B-Instruct-Lite\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":5.4e-7,\"caching_price\":5.4e-7,\"cached_price\":5.4e-7,\"output_price\":5.4e-7,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/meta-llama/Llama-2-70b-hf\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":9e-7,\"caching_price\":9e-7,\"cached_price\":9e-7,\"output_price\":9e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/meta-llama/Meta-Llama-3-70B-Instruct-Turbo\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8.8e-7,\"caching_price\":8.8e-7,\"cached_price\":8.8e-7,\"output_price\":8.8e-7,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/upstage/SOLAR-10.7B-Instruct-v1.0\",\"object\":\"model\",\"created\":1736964224,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":3e-7,\"cached_price\":3e-7,\"output_price\":3e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"together/Qwen/QwQ-32B-Preview\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":0.0000012,\"caching_price\":0.0000012,\"cached_price\":0.0000012,\"output_price\":0.0000012,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"together/meta-llama/Meta-Llama-Guard-3-8B\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":2e-7,\"caching_price\":2e-7,\"cached_price\":2e-7,\"output_price\":2e-7,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/deepseek-llm-67b-chat\",\"object\":\"model\",\"created\":1717095837,\"owned_by\":\"system\",\"input_price\":9e-7,\"caching_price\":9e-7,\"cached_price\":9e-7,\"output_price\":9e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"together/meta-llama/LlamaGuard-2-8b\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":2e-7,\"caching_price\":2e-7,\"cached_price\":2e-7,\"output_price\":2e-7,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":0.0000035,\"caching_price\":0.0000035,\"cached_price\":0.0000035,\"output_price\":0.0000035,\"max_output_tokens\":0,\"context_window\":130815,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/meta-llama/Llama-2-7b-chat-hf\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":2e-7,\"caching_price\":2e-7,\"cached_price\":2e-7,\"output_price\":2e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/Qwen/Qwen2.5-72B-Instruct-Turbo\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":0.0000012,\"caching_price\":0.0000012,\"cached_price\":0.0000012,\"output_price\":0.0000012,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"together/Qwen/Qwen2.5-7B-Instruct-Turbo\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":3e-7,\"cached_price\":3e-7,\"output_price\":3e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"together/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":6e-7,\"caching_price\":6e-7,\"cached_price\":6e-7,\"output_price\":6e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepHermes
        3 (Mistral 24B Preview) is an instruction-tuned language model by Nous Research
        based on Mistral-Small-24B, designed for chat, function calling, and advanced
        multi-turn reasoning. It introduces a dual-mode system that toggles between
        intuitive chat responses and structured \u201Cdeep reasoning\u201D mode using
        special system prompts. Fine-tuned via distillation from R1, it supports structured
        output (JSON mode) and function call syntax for agent-based applications.\\n\\nDeepHermes
        3 supports a **reasoning toggle via system prompt**, allowing users to switch
        between fast, intuitive responses and deliberate, multi-step reasoning. When
        activated with the following specific system instruction, the model enters
        a *\\\"deep thinking\\\"* mode\u2014generating extended chains of thought
        wrapped in `\\u003cthink\\u003e\\u003c/think\\u003e` tags before delivering
        a final answer. \\n\\nSystem Prompt: You are a deep thinking AI, you may use
        extremely long chains of thought to deeply consider the problem and deliberate
        with yourself via systematic reasoning processes to help come to a correct
        solution prior to answering. You should enclose your thoughts and internal
        monologue inside \\u003cthink\\u003e \\u003c/think\\u003e tags, and then provide
        your solution or response to the problem.\"},{\"id\":\"together/meta-llama/Llama-3.2-3B-Instruct-Turbo\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":6e-8,\"caching_price\":6e-8,\"cached_price\":6e-8,\"output_price\":6e-8,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/meta-llama/Llama-3.3-70B-Instruct-Turbo\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8.8e-7,\"caching_price\":8.8e-7,\"cached_price\":8.8e-7,\"output_price\":8.8e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/meta-llama/Llama-2-13b-chat-hf\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":2.2e-7,\"caching_price\":2.2e-7,\"cached_price\":2.2e-7,\"output_price\":2.2e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/Qwen/Qwen2.5-Coder-32B-Instruct\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":8e-7,\"cached_price\":8e-7,\"output_price\":8e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"together/deepseek-ai/DeepSeek-V3\",\"object\":\"model\",\"created\":1748631837,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.00000125,\"cached_price\":0.00000125,\"output_price\":0.00000125,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"together/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":1.8e-7,\"caching_price\":1.8e-7,\"cached_price\":1.8e-7,\"output_price\":1.8e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/meta-llama/Meta-Llama-3-8B-Instruct-Lite\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":1e-7,\"caching_price\":1e-7,\"cached_price\":1e-7,\"output_price\":1e-7,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/meta-llama/Llama-3-8b-chat-hf\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":2e-7,\"caching_price\":2e-7,\"cached_price\":2e-7,\"output_price\":2e-7,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"together/deepseek-ai/DeepSeek-R1\",\"object\":\"model\",\"created\":1748631837,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.000007,\"cached_price\":0.000003,\"output_price\":0.000007,\"max_output_tokens\":8192,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"together/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8.8e-7,\"caching_price\":8.8e-7,\"cached_price\":8.8e-7,\"output_price\":8.8e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"parasail/parasail-deepseek-r1\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.000003,\"cached_price\":0.000003,\"output_price\":0.000003,\"max_output_tokens\":8192,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"parasail/parasail-mistral-7b-instruct-03\",\"object\":\"model\",\"created\":1741278220,\"owned_by\":\"system\",\"input_price\":1.1e-7,\"caching_price\":1.1e-7,\"cached_price\":1.1e-7,\"output_price\":1.1e-7,\"max_output_tokens\":8192,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"parasail/parasail-skyfall-36b-v2-fp8\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":5e-7,\"caching_price\":5e-7,\"cached_price\":5e-7,\"output_price\":5e-7,\"max_output_tokens\":8192,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"parasail/parasail-eva-25-72b-v02-fp8\",\"object\":\"model\",\"created\":1741278220,\"owned_by\":\"system\",\"input_price\":7e-7,\"caching_price\":7e-7,\"cached_price\":7e-7,\"output_price\":7e-7,\"max_output_tokens\":8192,\"context_window\":32000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"parasail/parasail-wayfarer-70b-llama33-fp8\",\"object\":\"model\",\"created\":1741278220,\"owned_by\":\"system\",\"input_price\":7e-7,\"caching_price\":7e-7,\"cached_price\":7e-7,\"output_price\":7e-7,\"max_output_tokens\":8192,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"parasail/parasail-qwen25-vl-72b-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":7e-7,\"caching_price\":7e-7,\"cached_price\":7e-7,\"output_price\":7e-7,\"max_output_tokens\":8192,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"parasail/parasail-mistral-nemo\",\"object\":\"model\",\"created\":1741278220,\"owned_by\":\"system\",\"input_price\":1.1e-7,\"caching_price\":1.1e-7,\"cached_price\":1.1e-7,\"output_price\":1.1e-7,\"max_output_tokens\":8192,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"parasail/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":2.1e-7,\"caching_price\":8.5e-7,\"cached_price\":2.1e-7,\"output_price\":8.5e-7,\"max_output_tokens\":1048576,\"context_window\":1048576,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"parasail/meta-llama/Llama-4-Scout-17B-16E-Instruct\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":1.4e-7,\"caching_price\":5.8e-7,\"cached_price\":1.4e-7,\"output_price\":5.8e-7,\"max_output_tokens\":1048576,\"context_window\":1048576,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"parasail/parasail-anubis-pro\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":8e-7,\"cached_price\":8e-7,\"output_price\":8e-7,\"max_output_tokens\":8192,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"parasail/parasail-qwen-coder32b-longcontext-128\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":5e-7,\"caching_price\":5e-7,\"cached_price\":5e-7,\"output_price\":5e-7,\"max_output_tokens\":8192,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"parasail/parasail-gemma3-27b-it\",\"object\":\"model\",\"created\":1741963556,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5e-7,\"cached_price\":3e-7,\"output_price\":5e-7,\"max_output_tokens\":8192,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Gemma
        3 1B is the smallest of the new Gemma 3 family. It handles context windows
        up to 32k tokens, understands over 140 languages, and offers improved math,
        reasoning, and chat capabilities, including structured outputs and function
        calling. Note: Gemma 3 1B is not multimodal. For the smallest multimodal Gemma
        3 model, please see [Gemma 3 4B](google/gemma-3-4b-it)\"},{\"id\":\"parasail/parasail-mythomax-13b\",\"object\":\"model\",\"created\":1741278220,\"owned_by\":\"system\",\"input_price\":1.1e-7,\"caching_price\":1.1e-7,\"cached_price\":1.1e-7,\"output_price\":1.1e-7,\"max_output_tokens\":8192,\"context_window\":4000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet@eu-central-1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet@eu-north-1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-opus\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-4-opus@us-west-2\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-20250219@us-east-1\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-latest@us-east-2\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet@us-east-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-20250514@us-west-2\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet@eu-west-1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-20250219\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-20250514@eu-north-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-latest@us-east-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-latest@eu-west-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-20250219@eu-west-3\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-latest@us-west-2\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-20250514@eu-west-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-opus-20250514@us-east-1\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-latest@eu-central-1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet@us-east-2\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-latest@eu-west-1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet@us-west-2\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet@eu-north-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet@eu-west-3\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-20250219@us-east-2\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-20250514@eu-central-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-latest@us-east-2\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-20250514\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-latest@eu-central-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-opus-latest@us-west-2\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-20250219@us-west-2\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-20250514@us-east-2\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-opus-20250514@us-west-2\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-latest@eu-west-3\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-20250514@eu-west-3\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-latest@eu-west-3\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-opus-latest@us-east-2\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet@us-east-1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-20250219@eu-west-1\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet@eu-central-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-latest\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet@us-east-2\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-20250514@us-east-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-latest@eu-north-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-opus@us-east-1\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-4-opus@us-east-2\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet@eu-west-1\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet@us-west-2\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-opus-20250514\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-20250219@eu-central-1\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-20250219@eu-north-1\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-latest@eu-north-1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-opus-20250514@us-east-2\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-latest\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-sonnet-latest@us-west-2\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-4-opus-latest\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-4-opus-latest@us-east-1\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet@eu-west-3\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"bedrock/anthropic/claude-3-7-sonnet-latest@us-east-1\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/claude-3-7-sonnet\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/claude-3-7-sonnet:medium\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/claude-3-7-sonnet:low\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/claude-3-7-sonnet:64000\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/claude-3-7-sonnet:1024\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/o3-mini\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"cline/claude-3-7-sonnet:max\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/o3-mini:high\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"cline/claude-3-7-sonnet:8192\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/claude-3-7-sonnet:high\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/deepseek-reasoner:alpha\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":5.5e-7,\"caching_price\":5.5e-7,\"cached_price\":1.4e-7,\"output_price\":0.00000219,\"max_output_tokens\":8000,\"context_window\":64000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Fully
        open-source model \\u0026 technical report. Performance on par with OpenAI-o1.\"},{\"id\":\"cline/claude-3-7-sonnet:16384\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"cline/o3-mini:medium\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"cline/o3-mini:low\",\"object\":\"model\",\"created\":1738351721,\"owned_by\":\"system\",\"input_price\":0.0000011,\"caching_price\":0.0000011,\"cached_price\":5.5e-7,\"output_price\":0.0000044,\"max_output_tokens\":100000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"perplexity/sonar\",\"object\":\"model\",\"created\":1741313308,\"owned_by\":\"system\",\"input_price\":0.000001,\"caching_price\":0.000001,\"cached_price\":0.000001,\"output_price\":0.000001,\"max_output_tokens\":8192,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Lightweight
        offering with search grounding, quicker and cheaper than Sonar Pro.\"},{\"id\":\"perplexity/sonar-pro\",\"object\":\"model\",\"created\":1741313308,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.000003,\"cached_price\":0.000003,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":204800,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Premier
        search offering with search grounding, supporting advanced queries and follow-ups.\"},{\"id\":\"perplexity/sonar-reasoning-pro\",\"object\":\"model\",\"created\":1741313308,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":0.000002,\"output_price\":0.000008,\"max_output_tokens\":8192,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Premier
        reasoning offering powered by DeepSeek R1 with Chain of Thought (CoT).\"},{\"id\":\"deepinfra/deepseek-ai/DeepSeek-R1-Distill-Llama-70B\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":2.3e-7,\"caching_price\":2.3e-7,\"cached_price\":2.3e-7,\"output_price\":6.9e-7,\"max_output_tokens\":8192,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"deepinfra/deepseek-ai/DeepSeek-R1\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8.5e-7,\"caching_price\":8.5e-7,\"cached_price\":8.5e-7,\"output_price\":0.0000025,\"max_output_tokens\":8192,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"deepinfra/meta-llama/Meta-Llama-3.1-405B-Instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":8e-7,\"cached_price\":8e-7,\"output_price\":8e-7,\"max_output_tokens\":0,\"context_window\":130815,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"deepinfra/Qwen/Qwen2.5-72B-Instruct\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":2.3e-7,\"caching_price\":2.3e-7,\"cached_price\":2.3e-7,\"output_price\":4e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"deepinfra/meta-llama/Llama-3.3-70B-Instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":2.3e-7,\"caching_price\":2.3e-7,\"cached_price\":2.3e-7,\"output_price\":4e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"deepinfra/nvidia/Llama-3.1-Nemotron-70B-Instruct\",\"object\":\"model\",\"created\":1744123094,\"owned_by\":\"system\",\"input_price\":1.2e-7,\"caching_price\":1.2e-7,\"cached_price\":1.2e-7,\"output_price\":3e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Llama-3.3-Nemotron-Super-49B-v1
        is a large language model (LLM) optimized for advanced reasoning, conversational
        interactions, retrieval-augmented generation (RAG), and tool-calling tasks.
        Derived from Meta's Llama-3.3-70B-Instruct, it employs a Neural Architecture
        Search (NAS) approach, significantly enhancing efficiency and reducing memory
        requirements. This allows the model to support a context length of up to 128K
        tokens and fit efficiently on single high-performance GPUs, such as NVIDIA
        H200.\\n\\nNote: you must include `detailed thinking on` in the system prompt
        to enable reasoning. Please see [Usage Recommendations](https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1#quick-start-and-usage-recommendations)
        for more.\"},{\"id\":\"deepinfra/meta-llama/Llama-3.3-70B-Instruct-Turbo\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":1.2e-7,\"caching_price\":1.2e-7,\"cached_price\":1.2e-7,\"output_price\":3e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"deepinfra/meta-llama/Llama-3.2-11B-Vision-Instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":5.5e-8,\"caching_price\":5.5e-8,\"cached_price\":5.5e-8,\"output_price\":5.5e-8,\"max_output_tokens\":4096,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"deepinfra/meta-llama/Llama-3.2-90B-Vision-Instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":3.5e-7,\"caching_price\":3.5e-7,\"cached_price\":3.5e-7,\"output_price\":4e-7,\"max_output_tokens\":4096,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"deepinfra/Qwen/Qwen2.5-Coder-32B-Instruct\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":7e-8,\"caching_price\":7e-8,\"cached_price\":7e-8,\"output_price\":1.6e-7,\"max_output_tokens\":0,\"context_window\":16384,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\"object\":\"model\",\"created\":1715697754,\"owned_by\":\"system\",\"input_price\":2e-8,\"caching_price\":2e-8,\"cached_price\":2e-8,\"output_price\":5e-8,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"deepinfra/microsoft/phi-4\",\"object\":\"model\",\"created\":1746134561,\"owned_by\":\"system\",\"input_price\":7e-8,\"caching_price\":7e-8,\"cached_price\":7e-8,\"output_price\":1.4e-7,\"max_output_tokens\":0,\"context_window\":16384,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Phi-4-reasoning-plus
        is an enhanced 14B parameter model from Microsoft, fine-tuned from Phi-4 with
        additional reinforcement learning to boost accuracy on math, science, and
        code reasoning tasks. It uses the same dense decoder-only transformer architecture
        as Phi-4, but generates longer, more comprehensive outputs structured into
        a step-by-step reasoning trace and final answer.\\n\\nWhile it offers improved
        benchmark scores over Phi-4-reasoning across tasks like AIME, OmniMath, and
        HumanEvalPlus, its responses are typically ~50% longer, resulting in higher
        latency. Designed for English-only applications, it is well-suited for structured
        reasoning workflows where output quality takes priority over response speed.\"},{\"id\":\"deepinfra/Qwen/Qwen3-235B-A22B\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":2e-7,\"caching_price\":2e-7,\"cached_price\":2e-7,\"output_price\":6e-7,\"max_output_tokens\":4096,\"context_window\":40000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"deepinfra/Qwen/QwQ-32B\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":1.2e-7,\"caching_price\":1.2e-7,\"cached_price\":1.2e-7,\"output_price\":1.8e-7,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"deepinfra/Qwen/Qwen3-32B\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":1e-7,\"caching_price\":1e-7,\"cached_price\":1e-7,\"output_price\":3e-7,\"max_output_tokens\":0,\"context_window\":40000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"deepinfra/deepseek-ai/DeepSeek-V3\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8.5e-7,\"caching_price\":8.5e-7,\"cached_price\":8.5e-7,\"output_price\":9e-7,\"max_output_tokens\":8192,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":2.3e-7,\"caching_price\":2.3e-7,\"cached_price\":2.3e-7,\"output_price\":4e-7,\"max_output_tokens\":0,\"context_window\":130815,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"deepinfra/microsoft/WizardLM-2-8x22B\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":5e-7,\"caching_price\":5e-7,\"cached_price\":5e-7,\"output_price\":5e-7,\"max_output_tokens\":4096,\"context_window\":65536,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Phi-4-reasoning-plus
        is an enhanced 14B parameter model from Microsoft, fine-tuned from Phi-4 with
        additional reinforcement learning to boost accuracy on math, science, and
        code reasoning tasks. It uses the same dense decoder-only transformer architecture
        as Phi-4, but generates longer, more comprehensive outputs structured into
        a step-by-step reasoning trace and final answer.\\n\\nWhile it offers improved
        benchmark scores over Phi-4-reasoning across tasks like AIME, OmniMath, and
        HumanEvalPlus, its responses are typically ~50% longer, resulting in higher
        latency. Designed for English-only applications, it is well-suited for structured
        reasoning workflows where output quality takes priority over response speed.\"},{\"id\":\"anthropic/claude-3-opus-latest\",\"object\":\"model\",\"created\":1709596800,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":4096,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Powerful
        model for highly complex tasks. Top-level intelligence, fluency, and understanding.\"},{\"id\":\"anthropic/claude-3-7-sonnet-latest\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"anthropic/claude-3-sonnet-20240229\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.000003,\"cached_price\":0.000003,\"output_price\":0.000015,\"max_output_tokens\":4096,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Balance
        of intelligence and speed. Strong utility, balanced for scaled deployments\"},{\"id\":\"anthropic/claude-3-7-sonnet-20250219\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"anthropic/claude-3-5-haiku-20241022\",\"object\":\"model\",\"created\":1730678400,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":0.000001,\"cached_price\":8e-8,\"output_price\":0.000004,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Anthropic's
        fastest model. Intelligence at blazing speeds.\"},{\"id\":\"anthropic/claude-3-5-haiku-latest\",\"object\":\"model\",\"created\":1730678400,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":0.000001,\"cached_price\":8e-8,\"output_price\":0.000004,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Anthropic's
        fastest model. Intelligence at blazing speeds.\"},{\"id\":\"anthropic/claude-sonnet-4-20250514\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Sonnet 4 significantly improves on Sonnet 3.7's industry-leading capabilities,
        excelling in coding with a state-of-the-art 72.7% on SWE-bench. The model
        balances performance and efficiency for internal and external use cases, with
        enhanced steerability for greater control over implementations.\"},{\"id\":\"anthropic/claude-opus-4-20250514\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"anthropic/claude-3-5-sonnet-latest\",\"object\":\"model\",\"created\":1729558800,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"anthropic/claude-3-haiku-20240307\",\"object\":\"model\",\"created\":1730678400,\"owned_by\":\"system\",\"input_price\":2.5e-7,\"caching_price\":3e-7,\"cached_price\":3e-8,\"output_price\":0.00000125,\"max_output_tokens\":4096,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Fastest
        and most compact model for near-instant responsiveness. Quick and accurate
        targeted performance.\"},{\"id\":\"anthropic/claude-3-5-sonnet-20240620\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"anthropic/claude-3-5-sonnet-20241022\",\"object\":\"model\",\"created\":1718845200,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":8192,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"Anthropic's
        previous most intelligent model. High level of intelligence and capability.
        Excells in coding.\"},{\"id\":\"anthropic/claude-3-opus-20240229\",\"object\":\"model\",\"created\":1730678400,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":4096,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Powerful
        model for highly complex tasks. Top-level intelligence, fluency, and understanding.\"},{\"id\":\"google/gemini-1.5-pro-latest\",\"object\":\"model\",\"created\":1717604857,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.00000125,\"cached_price\":0.00000125,\"output_price\":0.000005,\"max_output_tokens\":8192,\"context_window\":2097152,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"google/gemini-2.5-flash\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"google/gemini-1.5-flash\",\"object\":\"model\",\"created\":1744918267,\"owned_by\":\"system\",\"input_price\":7.5e-8,\"caching_price\":7.5e-8,\"cached_price\":7.5e-8,\"output_price\":3e-7,\"max_output_tokens\":8192,\"context_window\":1048576,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"google/gemini-1.5-flash-8b\",\"object\":\"model\",\"created\":1744918267,\"owned_by\":\"system\",\"input_price\":7.5e-8,\"caching_price\":7.5e-8,\"cached_price\":7.5e-8,\"output_price\":3e-7,\"max_output_tokens\":8192,\"context_window\":1048576,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"google/gemini-1.5-flash-latest\",\"object\":\"model\",\"created\":1744918267,\"owned_by\":\"system\",\"input_price\":7.5e-8,\"caching_price\":7.5e-8,\"cached_price\":7.5e-8,\"output_price\":3e-7,\"max_output_tokens\":8192,\"context_window\":1048576,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"google/gemini-2.5-pro\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"google/gemini-2.5-flash-lite-preview-06-17\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":1e-7,\"caching_price\":3.5e-7,\"cached_price\":2.5e-8,\"output_price\":4e-7,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        smallest and most cost effective model, built for at scale usage.\"},{\"id\":\"google/gemini-1.5-pro\",\"object\":\"model\",\"created\":1717604857,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.00000125,\"cached_price\":0.00000125,\"output_price\":0.000005,\"max_output_tokens\":8192,\"context_window\":2097152,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"google/gemini-2.0-flash-001\",\"object\":\"model\",\"created\":1738769413,\"owned_by\":\"system\",\"input_price\":1e-7,\"caching_price\":1e-7,\"cached_price\":1e-7,\"output_price\":4e-7,\"max_output_tokens\":8192,\"context_window\":1048576,\"supports_caching\":false,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Gemini
        Flash 2.0 offers a significantly faster time to first token (TTFT) compared
        to [Gemini Flash 1.5](/google/gemini-flash-1.5), while maintaining quality
        on par with larger models like [Gemini Pro 1.5](/google/gemini-pro-1.5). It
        introduces notable enhancements in multimodal understanding, coding capabilities,
        complex instruction following, and function calling. These advancements come
        together to deliver more seamless and robust agentic experiences.\"},{\"id\":\"google/gemini-1.5-flash-8b-latest\",\"object\":\"model\",\"created\":1744918267,\"owned_by\":\"system\",\"input_price\":3.75e-8,\"caching_price\":3.75e-8,\"cached_price\":3.75e-8,\"output_price\":1.5e-7,\"max_output_tokens\":8192,\"context_window\":1048576,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"coding/gemini-2.5-pro@europe-west4\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-pro@us-east1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-pro@europe-central2\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-pro@europe-west1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-flash\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-flash@us-central1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-flash@europe-central2\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-pro\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-pro@us-south1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/claude-3-7-sonnet\",\"object\":\"model\",\"created\":1740422110,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Anthropic's
        most intelligent model. The first hybrid reasoning model on the market with
        the highest level of intelligence and capability with toggleable extended
        thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context
        handling, honesty, and image processing.\"},{\"id\":\"coding/gemini-2.5-flash@us-south1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-pro@us-central1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-flash@europe-west8\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-pro@us-west1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-pro@europe-north1\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-pro@europe-west8\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-pro-preview-05-06\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-flash@europe-north1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-flash@europe-west4\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-flash@us-east1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-flash@us-west1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-pro@us-east5\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/claude-4-sonnet\",\"object\":\"model\",\"created\":1747933971,\"owned_by\":\"system\",\"input_price\":0.000003,\"caching_price\":0.00000375,\"cached_price\":3e-7,\"output_price\":0.000015,\"max_output_tokens\":64000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Sonnet 4 significantly improves on Sonnet 3.7's industry-leading capabilities,
        excelling in coding with a state-of-the-art 72.7% on SWE-bench. The model
        balances performance and efficiency for internal and external use cases, with
        enhanced steerability for greater control over implementations.\"},{\"id\":\"coding/gemini-2.5-pro-preview-03-25\",\"object\":\"model\",\"created\":1746582113,\"owned_by\":\"system\",\"input_price\":0.00000125,\"caching_price\":0.000002375,\"cached_price\":3.1e-7,\"output_price\":0.00001,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Gemini
        2.5 Pro is Google\u2019s state-of-the-art AI model designed for advanced reasoning,
        coding, mathematics, and scientific tasks. It employs \u201Cthinking\u201D
        capabilities, enabling it to reason through responses with enhanced accuracy
        and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance
        on multiple benchmarks, including first-place positioning on the LMArena leaderboard,
        reflecting superior human-preference alignment and complex problem-solving
        abilities.\"},{\"id\":\"coding/gemini-2.5-flash-preview-05-20\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":1.5e-7,\"caching_price\":4e-7,\"cached_price\":1.5e-7,\"output_price\":6e-7,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"\"},{\"id\":\"coding/gemini-2.5-flash@us-east5\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/gemini-2.5-flash@europe-west1\",\"object\":\"model\",\"created\":1747765524,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":5.5e-7,\"cached_price\":7.5e-8,\"output_price\":0.0000025,\"max_output_tokens\":65535,\"context_window\":1048576,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":false,\"supports_reasoning\":true,\"description\":\"Google's
        first hybrid reasoning model which supports a 1M token context window and
        has thinking budgets. Most balanced Gemini model, optimized for low latency
        use cases.\"},{\"id\":\"coding/claude-4-opus\",\"object\":\"model\",\"created\":1747934845,\"owned_by\":\"system\",\"input_price\":0.000015,\"caching_price\":0.00001875,\"cached_price\":0.0000015,\"output_price\":0.000075,\"max_output_tokens\":32000,\"context_window\":200000,\"supports_caching\":true,\"supports_vision\":true,\"supports_computer_use\":true,\"supports_reasoning\":true,\"description\":\"Claude
        Opus 4 is Anthropic's most powerful model yet and the best coding model in
        the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers
        sustained performance on long-running tasks that require focused effort and
        thousands of steps, with the ability to work continuously for several hours\u2014dramatically
        outperforming all Sonnet models and significantly expanding what AI agents
        can accomplish.\"},{\"id\":\"netmind/deepseek-ai/DeepSeek-R1-0528\",\"object\":\"model\",\"created\":1748631837,\"owned_by\":\"system\",\"input_price\":5e-7,\"caching_price\":5e-7,\"cached_price\":5e-7,\"output_price\":0.000001,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":true,\"supports_reasoning\":false,\"description\":\"DeepSeek
        R1 is the latest open-source model released by the DeepSeek team, featuring
        impressive reasoning capabilities, particularly achieving performance comparable
        to OpenAI's o1 model in mathematics, coding, and reasoning tasks.\"},{\"id\":\"novita/meta-llama/llama-3.1-70b-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":3.4e-7,\"caching_price\":3.4e-7,\"cached_price\":3.4e-7,\"output_price\":3.9e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Meta's
        latest class of models, Llama 3.1, has launched with a variety of sizes and
        configurations. The 70B instruct-tuned version is optimized for high-quality
        dialogue use cases. It has demonstrated strong performance in human evaluations
        compared to leading closed-source models.\"},{\"id\":\"novita/microsoft/wizardlm-2-8x22b\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":6.2e-7,\"caching_price\":6.2e-7,\"cached_price\":6.2e-7,\"output_price\":6.2e-7,\"max_output_tokens\":0,\"context_window\":65535,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"WizardLM-2
        8x22B is Microsoft AI's most advanced Wizard model. It demonstrates highly
        competitive performance compared to leading proprietary models, and it consistently
        outperforms all existing state-of-the-art opensource models.\"},{\"id\":\"novita/meta-llama/llama-3-8b-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":4e-8,\"caching_price\":4e-8,\"cached_price\":4e-8,\"output_price\":4e-8,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Meta's
        latest class of model (Llama 3) launched with a variety of sizes \\u0026 flavors.
        This 8B instruct-tuned version was optimized for high quality dialogue usecases.
        It has demonstrated strong performance compared to leading closed-source models
        in human evaluations.\"},{\"id\":\"novita/meta-llama/llama-3.3-70b-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":3.9e-7,\"caching_price\":3.9e-7,\"cached_price\":3.9e-7,\"output_price\":3.9e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and
        instruction tuned generative model in 70B (text in/text out). The Llama 3.3
        instruction tuned text only model is optimized for multilingual dialogue use
        cases and outperforms many of the available open source and closed chat models
        on common industry benchmarks.\\n\\nSupported languages: English, German,
        French, Italian, Portuguese, Hindi, Spanish, and Thai.\"},{\"id\":\"novita/meta-llama/llama-3.2-3b-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":3e-8,\"caching_price\":3e-8,\"cached_price\":3e-8,\"output_price\":5e-8,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        Meta Llama 3.2 collection of multilingual large language models (LLMs) is
        a collection of pretrained and instruction-tuned generative models in 1B and
        3B sizes (text in/text out)\"},{\"id\":\"novita/gryphe/mythomax-l2-13b\",\"object\":\"model\",\"created\":1688259600,\"owned_by\":\"system\",\"input_price\":9e-8,\"caching_price\":9e-8,\"cached_price\":9e-8,\"output_price\":9e-8,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        idea behind this merge is that each layer is composed of several tensors,
        which are in turn responsible for specific functions. Using MythoLogic-L2's
        robust understanding as its input and Huginn's extensive writing capability
        as its output seems to have resulted in a model that exceeds at both, confirming
        my theory. (More details to be released at a later time).\"},{\"id\":\"novita/meta-llama/llama-3.2-11b-vision-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":6e-8,\"caching_price\":6e-8,\"cached_price\":6e-8,\"output_price\":6e-8,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Llama
        3.2 11B Vision is a multimodal model with 11 billion parameters, designed
        to handle tasks combining visual and textual data. It excels in tasks such
        as image captioning and visual question answering, bridging the gap between
        language generation and visual reasoning. Pre-trained on a massive dataset
        of image-text pairs, it performs well in complex, high-accuracy image analysis.
        Its ability to integrate visual understanding with language processing makes
        it an ideal solution for industries requiring comprehensive visual-linguistic
        AI applications, such as content creation, AI-driven customer service, and
        research.\"},{\"id\":\"novita/jondurbin/airoboros-l2-70b\",\"object\":\"model\",\"created\":1721222877,\"owned_by\":\"system\",\"input_price\":5e-7,\"caching_price\":5e-7,\"cached_price\":5e-7,\"output_price\":5e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"This
        is a fine-tuned Llama-2 model designed to support longer and more detailed
        writing prompts, as well as next-chapter generation. It also includes an experimental
        role-playing instruction set with multi-round dialogues, character interactions,
        and varying numbers of participants\"},{\"id\":\"novita/teknium/openhermes-2.5-mistral-7b\",\"object\":\"model\",\"created\":1713945673,\"owned_by\":\"system\",\"input_price\":1.7e-7,\"caching_price\":1.7e-7,\"cached_price\":1.7e-7,\"output_price\":1.7e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"OpenHermes
        2.5 Mistral 7B is a state of the art Mistral Fine-tune, a continuation of
        OpenHermes 2 model, which trained on additional code datasets.\"},{\"id\":\"novita/qwen/qwen-2-vl-72b-instruct\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":4.5e-7,\"caching_price\":4.5e-7,\"cached_price\":4.5e-7,\"output_price\":4.5e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen2
        VL 72B is a multimodal LLM from the Qwen Team with the following key enhancements:\\n\\nSoTA
        understanding of images of various resolution \\u0026 ratio: Qwen2-VL achieves
        state-of-the-art performance on visual understanding benchmarks, including
        MathVista, DocVQA, RealWorldQA, MTVQA, etc.\\n\\nUnderstanding videos of 20min+:
        Qwen2-VL can understand videos over 20 minutes for high-quality video-based
        question answering, dialog, content creation, etc.\\n\\nAgent that can operate
        your mobiles, robots, etc.: with the abilities of complex reasoning and decision
        making, Qwen2-VL can be integrated with devices like mobile phones, robots,
        etc., for automatic operation based on visual environment and text instructions.\\n\\nMultilingual
        Support: to serve global users, besides English and Chinese, Qwen2-VL now
        supports the understanding of texts in different languages inside images,
        including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.\"},{\"id\":\"novita/qwen/qwen2.5-vl-72b-instruct\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":8e-7,\"cached_price\":8e-7,\"output_price\":8e-7,\"max_output_tokens\":0,\"context_window\":96000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen2
        VL 72B is a multimodal LLM from the Qwen Team with the following key enhancements:\\n\\nSoTA
        understanding of images of various resolution \\u0026 ratio: Qwen2-VL achieves
        state-of-the-art performance on visual understanding benchmarks, including
        MathVista, DocVQA, RealWorldQA, MTVQA, etc.\\n\\nUnderstanding videos of 20min+:
        Qwen2-VL can understand videos over 20 minutes for high-quality video-based
        question answering, dialog, content creation, etc.\\n\\nAgent that can operate
        your mobiles, robots, etc.: with the abilities of complex reasoning and decision
        making, Qwen2-VL can be integrated with devices like mobile phones, robots,
        etc., for automatic operation based on visual environment and text instructions.\\n\\nMultilingual
        Support: to serve global users, besides English and Chinese, Qwen2-VL now
        supports the understanding of texts in different languages inside images,
        including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.\"},{\"id\":\"novita/deepseek/deepseek-r1-distill-qwen-14b\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":1.5e-7,\"caching_price\":1.5e-7,\"cached_price\":1.5e-7,\"output_price\":1.5e-7,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek
        R1 Distill Qwen 14B is a distilled large language model based on Qwen 2.5
        14B, using outputs from DeepSeek R1. It outperforms OpenAI's o1-mini across
        various benchmarks, achieving new state-of-the-art results for dense models.\\n\\nOther
        benchmark results include:\\n\\nAIME 2024 pass@1: 69.7\\nMATH-500 pass@1:
        93.9\\nCodeForces Rating: 1481\\nThe model leverages fine-tuning from DeepSeek
        R1's outputs, enabling competitive performance comparable to larger frontier
        models.\"},{\"id\":\"novita/mistralai/mistral-nemo\",\"object\":\"model\",\"created\":1718037161,\"owned_by\":\"system\",\"input_price\":1.7e-7,\"caching_price\":1.7e-7,\"cached_price\":1.7e-7,\"output_price\":1.7e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        12B parameter model with a 128k token context length built by Mistral in collaboration
        with NVIDIA. The model is multilingual, supporting English, French, German,
        Spanish, Italian, Portuguese, Chinese, Japanese, Korean, Arabic, and Hindi.
        It supports function calling and is released under the Apache 2.0 license.\"},{\"id\":\"novita/google/gemma-2-9b-it\",\"object\":\"model\",\"created\":1721318624,\"owned_by\":\"system\",\"input_price\":8e-8,\"caching_price\":8e-8,\"cached_price\":8e-8,\"output_price\":8e-8,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Gemma
        2 9B by Google is an advanced, open-source language model that sets a new
        standard for efficiency and performance in its size class.\\nDesigned for
        a wide variety of tasks, it empowers developers and researchers to build innovative
        applications, while maintaining accessibility, safety, and cost-effectiveness.\"},{\"id\":\"novita/qwen/qwen3-235b-a22b-fp8\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":2e-7,\"caching_price\":2e-7,\"cached_price\":2e-7,\"output_price\":8e-7,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"novita/meta-llama/llama-3-70b-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":5.1e-7,\"caching_price\":5.1e-7,\"cached_price\":5.1e-7,\"output_price\":7.4e-7,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Meta's
        latest class of model (Llama 3) launched with a variety of sizes \\u0026 flavors.
        This 70B instruct-tuned version was optimized for high quality dialogue usecases.
        It has demonstrated strong performance compared to leading closed-source models
        in human evaluations.\"},{\"id\":\"novita/deepseek/deepseek_v3\",\"object\":\"model\",\"created\":1748631837,\"owned_by\":\"system\",\"input_price\":8.9e-7,\"caching_price\":8.9e-7,\"cached_price\":8.9e-7,\"output_price\":8.9e-7,\"max_output_tokens\":0,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-V3
        is the latest model from the DeepSeek team, building upon the instruction
        following and coding abilities of the previous versions. Pre-trained on nearly
        15 trillion tokens, the reported evaluations reveal that the model outperforms
        other open-source models and rivals leading closed-source models.\"},{\"id\":\"novita/deepseek/deepseek-r1\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":0.000004,\"caching_price\":0.000004,\"cached_price\":0.000004,\"output_price\":0.000004,\"max_output_tokens\":0,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek
        R1 is the latest open-source model released by the DeepSeek team, featuring
        impressive reasoning capabilities, particularly achieving performance comparable
        to OpenAI's o1 model in mathematics, coding, and reasoning tasks.\"},{\"id\":\"novita/qwen/qwen-2.5-72b-instruct\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":3.8e-7,\"caching_price\":3.8e-7,\"cached_price\":3.8e-7,\"output_price\":4e-7,\"max_output_tokens\":0,\"context_window\":32000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen2.5
        is the latest series of Qwen large language models. For Qwen2.5, we release
        a number of base language models and instruction-tuned language models ranging
        from 0.5 to 72 billion parameters.\"},{\"id\":\"novita/sophosympatheia/midnight-rose-70b\",\"object\":\"model\",\"created\":1711065600,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":8e-7,\"cached_price\":8e-7,\"output_price\":8e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        merge with a complex family tree, this model was crafted for roleplaying and
        storytelling. Midnight Rose is a successor to Rogue Rose and Aurora Nights
        and improves upon them both. It wants to produce lengthy output by default
        and is the best creative writing merge produced so far by sophosympatheia.\"},{\"id\":\"novita/meta-llama/llama-4-maverick-17b-128e-instruct-fp8\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":2e-7,\"caching_price\":2e-7,\"cached_price\":2e-7,\"output_price\":8.5e-7,\"max_output_tokens\":1048576,\"context_window\":1048576,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response
        times are needed most.\"},{\"id\":\"novita/qwen/qwq-32b\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":1.8e-7,\"caching_price\":1.8e-7,\"cached_price\":1.8e-7,\"output_price\":2e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen3,
        the latest generation in the Qwen large language model series, features both
        dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual
        support, and advanced agent tasks. Its unique ability to switch seamlessly
        between a thinking mode for complex reasoning and a non-thinking mode for
        efficient dialogue ensures versatile, high-quality performance.\\n\\nSignificantly
        outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics,
        coding, commonsense reasoning, creative writing, and interactive dialogue
        capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3
        billion activated), 48 layers, 128 experts (8 activated per task), and supports
        up to 131K token contexts with YaRN, setting a new standard among open-source
        models.\"},{\"id\":\"novita/deepseek/deepseek-r1-turbo\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":7e-7,\"caching_price\":0.0000025,\"cached_price\":7e-7,\"output_price\":0.0000025,\"max_output_tokens\":0,\"context_window\":64000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek
        R1 is the latest open-source model released by the DeepSeek team, featuring
        impressive reasoning capabilities, particularly achieving performance comparable
        to OpenAI's o1 model in mathematics, coding, and reasoning tasks.\"},{\"id\":\"novita/nousresearch/hermes-2-pro-llama-3-8b\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":1.4e-7,\"caching_price\":1.4e-7,\"cached_price\":1.4e-7,\"output_price\":1.4e-7,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Hermes
        2 Pro is an upgraded, retrained version of Nous Hermes 2, consisting of an
        updated and cleaned version of the OpenHermes 2.5 Dataset, as well as a newly
        introduced Function Calling and JSON Mode dataset developed in-house.\"},{\"id\":\"novita/deepseek/deepseek-prover-v2-671b\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":7e-7,\"caching_price\":7e-7,\"cached_price\":7e-7,\"output_price\":0.0000025,\"max_output_tokens\":0,\"context_window\":160000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek-R1-Distill-Qwen-7B
        is a 7 billion parameter dense language model distilled from DeepSeek-R1,
        leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's
        larger models. The distillation process transfers advanced reasoning, math,
        and code capabilities into a smaller, more efficient model architecture based
        on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical
        benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189),
        and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive
        accuracy relative to larger models while maintaining smaller inference costs.\"},{\"id\":\"novita/deepseek/deepseek-r1-distill-qwen-32b\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":3e-7,\"caching_price\":3e-7,\"cached_price\":3e-7,\"output_price\":3e-7,\"max_output_tokens\":0,\"context_window\":12800,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek
        R1 Distill Qwen 32B is a distilled large language model based on Qwen 2.5
        32B, using outputs from DeepSeek R1. It outperforms OpenAI's o1-mini across
        various benchmarks, achieving new state-of-the-art results for dense models.\\n\\nOther
        benchmark results include:\\nAIME 2024 pass@1: 72.6\\nMATH-500 pass@1: 94.3\\nCodeForces
        Rating: 1691\\nThe model leverages fine-tuning from DeepSeek R1's outputs,
        enabling competitive performance comparable to larger frontier models.\"},{\"id\":\"novita/meta-llama/llama-3.1-8b-instruct-bf16\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":6e-8,\"caching_price\":6e-8,\"cached_price\":6e-8,\"output_price\":6e-8,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Meta's
        latest class of models, Llama 3.1, launched with a variety of sizes and configurations.
        The 8B instruct-tuned version is particularly fast and efficient. It has demonstrated
        strong performance in human evaluations, \\n                   outperforming
        several leading closed-source models.\"},{\"id\":\"novita/sao10k/l3-8b-lunaris\",\"object\":\"model\",\"created\":1734535928,\"owned_by\":\"system\",\"input_price\":5e-8,\"caching_price\":5e-8,\"cached_price\":5e-8,\"output_price\":5e-8,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        generalist / roleplaying model merge based on Llama 3.\"},{\"id\":\"novita/nousresearch/nous-hermes-llama2-13b\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":1.7e-7,\"caching_price\":1.7e-7,\"cached_price\":1.7e-7,\"output_price\":1.7e-7,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Nous-Hermes-Llama2-13b
        is a state-of-the-art language model fine-tuned on over 300,000 instructions.
        This model was fine-tuned by Nous Research, with Teknium and Emozilla leading
        the fine tuning process and dataset curation, Redmond AI sponsoring the compute,
        and several other contributors.\"},{\"id\":\"novita/qwen/qwen-2-7b-instruct\",\"object\":\"model\",\"created\":1745882204,\"owned_by\":\"system\",\"input_price\":5.4e-8,\"caching_price\":5.4e-8,\"cached_price\":5.4e-8,\"output_price\":5.4e-8,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Qwen2
        is the newest series in the Qwen large language model family. Qwen2 7B is
        a transformer-based model that demonstrates exceptional performance in language
        understanding, multilingual capabilities, programming, mathematics, and reasoning.\"},{\"id\":\"novita/mistralai/mistral-7b-instruct\",\"object\":\"model\",\"created\":1718037161,\"owned_by\":\"system\",\"input_price\":5.9e-8,\"caching_price\":5.9e-8,\"cached_price\":5.9e-8,\"output_price\":5.9e-8,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"A
        high-performing, industry-standard 7.3B parameter model, with optimizations
        for speed and context length.\"},{\"id\":\"novita/deepseek/deepseek-r1-distill-llama-70b\",\"object\":\"model\",\"created\":1738263837,\"owned_by\":\"system\",\"input_price\":8e-7,\"caching_price\":8e-7,\"cached_price\":8e-7,\"output_price\":8e-7,\"max_output_tokens\":0,\"context_window\":32000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek
        R1 Distill LLama 70B\"},{\"id\":\"novita/deepseek/deepseek-v3-0324\",\"object\":\"model\",\"created\":1748631837,\"owned_by\":\"system\",\"input_price\":4e-7,\"caching_price\":4e-7,\"cached_price\":4e-7,\"output_price\":0.0000013,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek
        R1 is the latest open-source model released by the DeepSeek team, featuring
        impressive reasoning capabilities, particularly achieving performance comparable
        to OpenAI's o1 model in mathematics, coding, and reasoning tasks.\"},{\"id\":\"novita/meta-llama/llama-3.2-1b-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":2e-8,\"caching_price\":2e-8,\"cached_price\":2e-8,\"output_price\":2e-8,\"max_output_tokens\":0,\"context_window\":131000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        Meta Llama 3.2 collection of multilingual large language models (LLMs) is
        a collection of pretrained and instruction-tuned generative models in 1B and
        3B sizes (text in/text out).\"},{\"id\":\"novita/openchat/openchat-7b\",\"object\":\"model\",\"created\":1721999372,\"owned_by\":\"system\",\"input_price\":6e-8,\"caching_price\":6e-8,\"cached_price\":6e-8,\"output_price\":6e-8,\"max_output_tokens\":0,\"context_window\":4096,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"OpenChat
        7B is a library of open-source language models, fine-tuned with \\\"C-RLFT
        (Conditioned Reinforcement Learning Fine-Tuning)\\\" - a strategy inspired
        by offline reinforcement learning. It has been trained on mixed-quality data
        without preference labels.\"},{\"id\":\"novita/meta-llama/llama-3.1-8b-instruct-max\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":5e-8,\"caching_price\":5e-8,\"cached_price\":5e-8,\"output_price\":5e-8,\"max_output_tokens\":0,\"context_window\":16384,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Meta's
        latest class of models, Llama 3.1, launched with a variety of sizes and configurations.
        The 8B instruct-tuned version is particularly fast and efficient. It has demonstrated
        strong performance in human evaluations, outperforming several leading closed-source
        models.\"},{\"id\":\"novita/Sao10K/L3-8B-Stheno-v3.2\",\"object\":\"model\",\"created\":1734535928,\"owned_by\":\"system\",\"input_price\":5e-8,\"caching_price\":5e-8,\"cached_price\":5e-8,\"output_price\":5e-8,\"max_output_tokens\":0,\"context_window\":8192,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Sao10K/L3-8B-Stheno-v3.2
        is a highly skilled actor that excels at fully immersing itself in any role
        assigned.\"},{\"id\":\"novita/deepseek/deepseek-v3-turbo\",\"object\":\"model\",\"created\":1748631837,\"owned_by\":\"system\",\"input_price\":4e-7,\"caching_price\":4e-7,\"cached_price\":4e-7,\"output_price\":0.0000013,\"max_output_tokens\":0,\"context_window\":128000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"DeepSeek
        R1 is the latest open-source model released by the DeepSeek team, featuring
        impressive reasoning capabilities, particularly achieving performance comparable
        to OpenAI's o1 model in mathematics, coding, and reasoning tasks.\"},{\"id\":\"novita/sao10k/l3-70b-euryale-v2.1\",\"object\":\"model\",\"created\":1734535928,\"owned_by\":\"system\",\"input_price\":0.00000148,\"caching_price\":0.00000148,\"cached_price\":0.00000148,\"output_price\":0.00000148,\"max_output_tokens\":0,\"context_window\":16000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"The
        uncensored llama3 model is a powerhouse of creativity, excelling in both roleplay
        and story writing. It offers a liberating experience during roleplays, free
        from any restrictions. This model stands out for its immense creativity, boasting
        a vast array of unique ideas and plots, truly a treasure trove for those seeking
        originality. Its unrestricted nature during roleplays allows for the full
        breadth of imagination to unfold, akin to an enhanced, big-brained version
        of Stheno. Perfect for creative minds seeking a boundless platform for their
        imaginative expressions, the uncensored llama3 model is an ideal choice\"},{\"id\":\"novita/sao10k/l31-70b-euryale-v2.2\",\"object\":\"model\",\"created\":1734535928,\"owned_by\":\"system\",\"input_price\":0.00000148,\"caching_price\":0.00000148,\"cached_price\":0.00000148,\"output_price\":0.00000148,\"max_output_tokens\":0,\"context_window\":16000,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Euryale
        L3.1 70B v2.2 is a model focused on creative roleplay from Sao10k. It is the
        successor of Euryale L3 70B v2.1.\"},{\"id\":\"novita/meta-llama/llama-3.1-8b-instruct\",\"object\":\"model\",\"created\":1738865908,\"owned_by\":\"system\",\"input_price\":5e-8,\"caching_price\":5e-8,\"cached_price\":5e-8,\"output_price\":5e-8,\"max_output_tokens\":0,\"context_window\":16384,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Meta's
        latest class of models, Llama 3.1, launched with a variety of sizes and configurations.
        The 8B instruct-tuned version is particularly fast and efficient. It has demonstrated
        strong performance in human evaluations, outperforming several leading closed-source
        models.\"},{\"id\":\"mistral/open-mistral-7b\",\"object\":\"model\",\"created\":1708792361,\"owned_by\":\"system\",\"input_price\":2.5e-7,\"caching_price\":2.5e-7,\"cached_price\":2.5e-7,\"output_price\":2.5e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Magistral
        Small is a 24B parameter instruction-tuned model based on Mistral-Small-3.1
        (2503), enhanced through supervised fine-tuning on traces from Magistral Medium
        and further refined via reinforcement learning. It is optimized for reasoning
        and supports a wide multilingual range, including over 20 languages.\"},{\"id\":\"mistral/mistral-large-latest\",\"object\":\"model\",\"created\":1708792361,\"owned_by\":\"system\",\"input_price\":0.000002,\"caching_price\":0.000002,\"cached_price\":0.000002,\"output_price\":0.000006,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Magistral
        Small is a 24B parameter instruction-tuned model based on Mistral-Small-3.1
        (2503), enhanced through supervised fine-tuning on traces from Magistral Medium
        and further refined via reinforcement learning. It is optimized for reasoning
        and supports a wide multilingual range, including over 20 languages.\"},{\"id\":\"mistral/devstral-small-latest\",\"object\":\"model\",\"created\":1736964224,\"owned_by\":\"system\",\"input_price\":1e-7,\"caching_price\":1e-7,\"cached_price\":1e-7,\"output_price\":3e-7,\"max_output_tokens\":0,\"context_window\":131072,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"\"},{\"id\":\"mistral/mistral-small-latest\",\"object\":\"model\",\"created\":1708792361,\"owned_by\":\"system\",\"input_price\":1e-7,\"caching_price\":1e-7,\"cached_price\":1e-7,\"output_price\":3e-7,\"max_output_tokens\":0,\"context_window\":32768,\"supports_caching\":false,\"supports_vision\":false,\"supports_computer_use\":false,\"supports_reasoning\":false,\"description\":\"Magistral
        Small is a 24B parameter instruction-tuned model based on Mistral-Small-3.1
        (2503), enhanced through supervised fine-tuning on traces from Magistral Medium
        and further refined via reinforcement learning. It is optimized for reasoning
        and supports a wide multilingual range, including over 20 languages.\"}]}\n"
    headers:
      content-length:
      - '228652'
      content-type:
      - application/json
      date:
      - Fri, 11 Jul 2025 00:02:11 GMT
      fly-request-id:
      - 01JZVCM8Q2C3TAVVSKEKEE7N5G-sea
      server:
      - Fly/a608e03f9 (2025-07-10)
      transfer-encoding:
      - chunked
      vary:
      - Origin
      via:
      - 1.1 fly.io, 1.1 fly.io
    status:
      code: 200
      message: OK
- request:
    body: '{"messages":[{"role":"user","content":[{"type":"text","text":"Describe
      image in three words"},{"type":"image_url","image_url":{"url":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKYAAAEaAgMAAADmmcReAAAACVBMVEX///8A/wD+AQASdAFKAAAAR0lEQVR42u3YMREAMAjAwC5d6q8mUYkEVuA+8yvIkVr0oghFURRFURRFURRFUdRCkSRJM7u/CEVRFEVRFEVRFEXRpdQXkcaVBRUPn8UJn6QAAAAASUVORK5CYII="}}]}],"model":"google/gemini-2.5-pro","stream":true,"stream_options":{"include_usage":true}}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '449'
      content-type:
      - application/json
      host:
      - router.requesty.ai
      http-referer:
      - https://llm.datasette.io/
      user-agent:
      - OpenAI/Python 1.82.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.82.0
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.13.5
      x-title:
      - LLM
    method: POST
    uri: https://router.requesty.ai/v1/chat/completions
  response:
    body:
      string: 'data: {"choices":[{"delta":{"content":"Red, green, rectangles.","role":"assistant"},"finish_reason":"stop","index":0}],"created":1752192146,"id":"rqsty-cmpl-738852b4-4321-4ce0-87ed-5c8d2664a767","model":"gemini-2.5-pro","object":"chat.completion.chunk","usage":{"completion_tokens":6,"prompt_tokens":264,"total_tokens":1397}}


        data: [DONE]


        '
    headers:
      Content-Length:
      - '341'
      connection:
      - keep-alive
      content-type:
      - text/event-stream
      date:
      - Fri, 11 Jul 2025 00:02:26 GMT
      fly-request-id:
      - 01JZVCM92Y6MJ89K3HN2058S8Z-sea
      server:
      - Fly/a608e03f9 (2025-07-10)
      vary:
      - Origin
      via:
      - 1.1 fly.io, 1.1 fly.io
    status:
      code: 200
      message: OK
version: 1
